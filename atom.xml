<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>victory的博客</title>
  
  <subtitle>长安一片月，万户捣衣声</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-08-23T14:36:04.760Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>victory-liao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>VPN | SSL VPN</title>
    <link href="http://example.com/2024/08/23/SSLVPN/"/>
    <id>http://example.com/2024/08/23/SSLVPN/</id>
    <published>2024-08-23T14:33:17.000Z</published>
    <updated>2024-08-23T14:36:04.760Z</updated>
    
    <content type="html"><![CDATA[<p><code>SSL VPN</code>是以<code>SSL</code>加密技术为基础的<code>VPN</code>技术，利用<code>SSL</code>提供的安全机制，为用户<code>远程访问</code>公司内部网络提供了安全保证。</p><p>SSL VPN的典型组网架构如下：</p><p>![](./SSLVPN/SSL VPN组网.png)</p><span id="more"></span><p>SSL VPN的三种接入方式：</p><ol><li><p>Web接入方式</p><p><img src="/2024/08/23/SSLVPN/web.png"></p></li><li><p>TCP接入方式</p><p><img src="/2024/08/23/SSLVPN/tcp.png"></p></li><li><p>IP接入方式</p><p><img src="/2024/08/23/SSLVPN/ip.png"></p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;SSL VPN&lt;/code&gt;是以&lt;code&gt;SSL&lt;/code&gt;加密技术为基础的&lt;code&gt;VPN&lt;/code&gt;技术，利用&lt;code&gt;SSL&lt;/code&gt;提供的安全机制，为用户&lt;code&gt;远程访问&lt;/code&gt;公司内部网络提供了安全保证。&lt;/p&gt;
&lt;p&gt;SSL VPN的典型组网架构如下：&lt;/p&gt;
&lt;p&gt;![](./SSLVPN/SSL VPN组网.png)&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VPN" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/"/>
    
    <category term="SSL VPN" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/SSL-VPN/"/>
    
    
    <category term="VPN" scheme="http://example.com/tags/VPN/"/>
    
    <category term="SSL VPN" scheme="http://example.com/tags/SSL-VPN/"/>
    
  </entry>
  
  <entry>
    <title>智算网络 | Scale up和Scale out网络</title>
    <link href="http://example.com/2024/08/23/Scaleup%E5%92%8CScaleout%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2024/08/23/Scaleup%E5%92%8CScaleout%E7%BD%91%E7%BB%9C/</id>
    <published>2024-08-23T14:29:48.000Z</published>
    <updated>2024-08-23T14:31:41.943Z</updated>
    
    <content type="html"><![CDATA[<p>智算网络包含Scale-up网络和Scale-out网络两张网络。</p><span id="more"></span><p>Scale-up网络描述的是单个机器内GPU、CPU、内存等连接在一起构成的网络，着重单机性能的提升，例如通过增加GPU的数量或增加CPU的数量、增加内存容量来提升单机的计算效率与吞吐量。单机内部不同芯片的连接采用PCIe，GPU之间的连接也可通过NVLink进行连接。</p><p>Scale-out网络描述的是多个算力机器连接起来构成的网络，属于机间互联，目的是为了突破单机性能，通过机间互联合并算力组成一个大的算力网络为大数据处理、大模型训练提供支持。不同机器间的连接可采用RDMA（比较高效的两种是RoCEv2和IB）。</p><p>参考链接1：<a href="https://mp.weixin.qq.com/s/X9if693QD1w3rU3RNDy2Nw">智算网络中Scale-out网络和Scale-up网络的本质区别是什么？</a></p><p>参考链接2：<a href="https://mp.weixin.qq.com/s/fyPFr6aBds3dIV2sc1B6Nw">用于智算场景的Scale-up互联技术分析</a></p><p>参考链接3：<a href="https://mp.weixin.qq.com/s/b6Qf8MD-FG1Ve_PlUyFb2g">CXL，AI时代的“运力”引擎</a></p><p>参考链接4：<a href="https://mp.weixin.qq.com/s/kJZFzX0rWiPtxMkrI8i6TA">Scale-up与Scale-out有什么不同？</a></p><p>参考链接5：<a href="https://mp.weixin.qq.com/s/RyApSIT-wyrEzbiWEsvgZQ">AIGC为什么要区分Scale-out和Scale-up两张网络？</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;智算网络包含Scale-up网络和Scale-out网络两张网络。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="智算中心" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    
    <category term="智算网络：Scale up和Scale out网络" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/%E6%99%BA%E7%AE%97%E7%BD%91%E7%BB%9C%EF%BC%9AScale-up%E5%92%8CScale-out%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="IB" scheme="http://example.com/tags/IB/"/>
    
    <category term="RDMA" scheme="http://example.com/tags/RDMA/"/>
    
    <category term="RoCEv2" scheme="http://example.com/tags/RoCEv2/"/>
    
    <category term="PCIe" scheme="http://example.com/tags/PCIe/"/>
    
    <category term="智算网络" scheme="http://example.com/tags/%E6%99%BA%E7%AE%97%E7%BD%91%E7%BB%9C/"/>
    
    <category term="Scale up" scheme="http://example.com/tags/Scale-up/"/>
    
    <category term="Scale out" scheme="http://example.com/tags/Scale-out/"/>
    
    <category term="AIGC" scheme="http://example.com/tags/AIGC/"/>
    
  </entry>
  
  <entry>
    <title>GPU | CUDA核心与TensorCore的区别</title>
    <link href="http://example.com/2024/08/08/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensorCore%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://example.com/2024/08/08/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensorCore%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2024-08-08T12:45:17.000Z</published>
    <updated>2024-08-08T12:51:05.853Z</updated>
    
    <content type="html"><![CDATA[<p><code>CUDA核心</code>和<code>Tensor Core</code>是<code>NVIDIA GPU</code>中两种不同类型的计算核心且两种核心存在明显的差别，<code>CUDA核心数量</code>和<code>Tensor Core数量</code>是反映GPU计算性能的重要参数，那么CUDA核心与Tensor Core到底是什么？</p><span id="more"></span><p><code>CUDA</code>是<code>NVIDIA</code>发明的<code>并行计算平台</code>和编程模型，<code>CUDA</code>利用<code>GPU</code>强大的<code>并行处理能力</code>提升计算的性能。<code>CUDA核心</code>主要用于执行标准的<code>浮点运算</code>（单精度或双精度），每个<code>CUDA核心</code>每个时钟周期可执行<code>乘加操作</code>，适用于各种<code>通用</code>计算任务。</p><p><code>Tensor Core</code>专为<code>深度学习</code>和<code>AI</code>工作负载设计，用于<code>加速矩阵运算</code>，特别是处理<code>半精度(FP16)</code>和<code>全精度(FP32)</code>的<code>矩阵乘法和累加操作</code>，能够优化<code>深度学习训练和推理</code>过程。第一代<code>Tensor Core</code>是随着<code>Volta</code>架构一起推出的，一代<code>Tensor Core</code>允许两个 4 x 4 FP16 矩阵相乘并添加到一个 4 x 4 FP16 或 FP32 矩阵中（如下图所示），可以实现<code>混合精度训练</code>。</p><p><img src="/2024/08/08/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensorCore%E7%9A%84%E5%8C%BA%E5%88%AB/MAC.png"></p><p>参考链接：<a href="https://developer.volcengine.com/articles/7387624872916353043">一文理解 GPU 张量核心（Tensor Core）</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;CUDA核心&lt;/code&gt;和&lt;code&gt;Tensor Core&lt;/code&gt;是&lt;code&gt;NVIDIA GPU&lt;/code&gt;中两种不同类型的计算核心且两种核心存在明显的差别，&lt;code&gt;CUDA核心数量&lt;/code&gt;和&lt;code&gt;Tensor Core数量&lt;/code&gt;是反映GPU计算性能的重要参数，那么CUDA核心与Tensor Core到底是什么？&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="GPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/"/>
    
    <category term="CUDA核心与Tensor Core的区别" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensor-Core%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CUDA" scheme="http://example.com/tags/CUDA/"/>
    
    <category term="Tensor Core" scheme="http://example.com/tags/Tensor-Core/"/>
    
  </entry>
  
  <entry>
    <title>指令集 | 指令集以及国产处理器现状</title>
    <link href="http://example.com/2024/08/08/%E6%8C%87%E4%BB%A4%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E7%8E%B0%E7%8A%B6/"/>
    <id>http://example.com/2024/08/08/%E6%8C%87%E4%BB%A4%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E7%8E%B0%E7%8A%B6/</id>
    <published>2024-08-08T12:40:13.000Z</published>
    <updated>2024-08-08T12:50:50.340Z</updated>
    
    <content type="html"><![CDATA[<ul><li>指令集以及对应的国产处理器<ul><li>CISC<ul><li>X86<ul><li>海光</li><li>兆芯</li></ul></li><li>……</li></ul></li><li>RISC<ul><li>ARM<ul><li>鲲鹏、飞腾、珠峰</li></ul></li><li>RISC-V</li><li>MIPS<ul><li>龙芯 LoongArch</li></ul></li><li>Alpha<ul><li>申威 SW_64</li></ul></li><li>……</li></ul></li></ul></li></ul><span id="more"></span><p>参考链接：<a href="https://mp.weixin.qq.com/s/XA2UtNighbmaAsi2Fua93A">一文读懂面向数据中心的高性能通用RISC-V处理器技术（上）</a></p>]]></content>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;指令集以及对应的国产处理器&lt;ul&gt;
&lt;li&gt;CISC&lt;ul&gt;
&lt;li&gt;X86&lt;ul&gt;
&lt;li&gt;海光&lt;/li&gt;
&lt;li&gt;兆芯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RISC&lt;ul&gt;
&lt;li&gt;ARM&lt;ul&gt;
&lt;li&gt;鲲鹏、飞腾、珠峰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RISC-V&lt;/li&gt;
&lt;li&gt;MIPS&lt;ul&gt;
&lt;li&gt;龙芯 LoongArch&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Alpha&lt;ul&gt;
&lt;li&gt;申威 SW_64&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="CPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/"/>
    
    <category term="指令集以及国产处理器现状" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E7%8E%B0%E7%8A%B6/"/>
    
    
    <category term="指令集" scheme="http://example.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="CISC" scheme="http://example.com/tags/CISC/"/>
    
    <category term="RISC" scheme="http://example.com/tags/RISC/"/>
    
    <category term="X86" scheme="http://example.com/tags/X86/"/>
    
    <category term="ARM" scheme="http://example.com/tags/ARM/"/>
    
    <category term="国产处理器" scheme="http://example.com/tags/%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8/"/>
    
    <category term="RISC-V" scheme="http://example.com/tags/RISC-V/"/>
    
  </entry>
  
  <entry>
    <title>后端优化 | 循环优化</title>
    <link href="http://example.com/2024/07/22/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2024/07/22/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/</id>
    <published>2024-07-22T15:23:23.000Z</published>
    <updated>2024-07-22T15:30:28.594Z</updated>
    
    <content type="html"><![CDATA[<p>采用深度学习编译器对深度学习代码进行编译时，在编译器后端会对IR代码进行后端优化，循环优化就包括在后端优化中，后端优化能够加速代码的运行效率。深度学习编译器编译流程如下图所示：</p><span id="more"></span><p><img src="/2024/07/22/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B.png"></p><p>循环优化方式：</p><ul><li><p>循环融合（loop fusion）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sayHello</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sayBye</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;bye&quot;</span>)</span><br><span class="line"><span class="comment"># 融合前</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    sayHello()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    sayBye()</span><br><span class="line"><span class="comment"># 融合后（将两个循环融合为一个）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    sayHello()</span><br><span class="line">    sayBye()</span><br></pre></td></tr></table></figure></li><li><p>循环重新排序（loop reorder）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重排序前</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 重排序后（采用迭代次数较小的循环驱动内层迭代次数较大的循环能减少内存的消耗）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li><li><p>循环展开（loop unrolling）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展开前</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    sayHello()</span><br><span class="line"><span class="comment"># 展开后</span></span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br></pre></td></tr></table></figure></li><li><p>循环分块（loop tiling）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_2d_array</span>(<span class="params">n, A</span>):</span></span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="built_in">sum</span> += A[i][j]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_2d_array</span>(<span class="params">n, A</span>) &#123;</span></span><br><span class="line"><span class="function">    <span class="title">sum</span> = 0</span></span><br><span class="line"><span class="function">    <span class="title">block_size</span> = 8</span></span><br><span class="line"><span class="function">    <span class="title">for</span> <span class="title">i</span> <span class="title">in</span> <span class="title">range</span>(<span class="params"><span class="number">0</span>, n, block_size</span>):</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n, block_size):</span><br><span class="line">    <span class="keyword">for</span> bi <span class="keyword">in</span> <span class="built_in">range</span>(i, i + block_size):</span><br><span class="line">    <span class="keyword">for</span> bj <span class="keyword">in</span> <span class="built_in">range</span>(j, j + block_size):</span><br><span class="line">    <span class="built_in">sum</span> += A[bi][bj]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;采用深度学习编译器对深度学习代码进行编译时，在编译器后端会对IR代码进行后端优化，循环优化就包括在后端优化中，后端优化能够加速代码的运行效率。深度学习编译器编译流程如下图所示：&lt;/p&gt;</summary>
    
    
    
    <category term="编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="深度学习编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="后端优化" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="循环优化" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="编译器" scheme="http://example.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="后端优化" scheme="http://example.com/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="循环优化" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="循环融合" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E8%9E%8D%E5%90%88/"/>
    
    <category term="循环重排序" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
    <category term="循环展开" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/"/>
    
    <category term="循环分块" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E5%88%86%E5%9D%97/"/>
    
  </entry>
  
  <entry>
    <title>RDMA | IB与RoCEv2的对比</title>
    <link href="http://example.com/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    <id>http://example.com/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/</id>
    <published>2024-07-22T15:22:55.000Z</published>
    <updated>2024-07-22T15:27:11.741Z</updated>
    
    <content type="html"><![CDATA[<p>Nvidia Infiniband 与 RoCEv2的对比：</p><p><img src="/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94.png"></p><p>参考链接：<a href="https://mp.weixin.qq.com/s/kzcrq9ycET_K7TrIQT_nSg">Infiniband和RoCEv2，以及RDMA技术的未来</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Nvidia Infiniband 与 RoCEv2的对比：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%</summary>
      
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="RDMA" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RDMA/"/>
    
    <category term="IB与RoCEv2的对比" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RDMA/IB%E4%B8%8ERoCEv2%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    
    
    <category term="IB" scheme="http://example.com/tags/IB/"/>
    
    <category term="RDMA" scheme="http://example.com/tags/RDMA/"/>
    
    <category term="RoCEv2" scheme="http://example.com/tags/RoCEv2/"/>
    
  </entry>
  
  <entry>
    <title>TVM | TVM介绍</title>
    <link href="http://example.com/2024/07/22/TVM%E4%BB%8B%E7%BB%8D/"/>
    <id>http://example.com/2024/07/22/TVM%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-07-22T15:22:16.000Z</published>
    <updated>2024-07-22T15:25:11.708Z</updated>
    
    <content type="html"><![CDATA[<p>参考文章：<a href="https://www.zhihu.com/question/532085071/answer/3154629417">(38 封私信 / 80 条消息) 深度学习编译器研发工程师的工作主要是集中于编译技术的前端、中端还是后端？ - 知乎 (zhihu.com)</a></p><p>参考视频：<a href="https://www.bilibili.com/video/BV1u6421M7jN/?spm_id_from=333.788&vd_source=0d5e0d352ee1cac3b12442c119f31bfc">【3rd-party】20240215 深度学习编译技术及TVM实践分享_哔哩哔哩_bilibili</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考文章：&lt;a href=&quot;https://www.zhihu.com/question/532085071/answer/3154629417&quot;&gt;(38 封私信 / 80 条消息) 深度学习编译器研发工程师的工作主要是集中于编译技术的前端、中端还是后端？ - 知乎 (zh</summary>
      
    
    
    
    <category term="编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="深度学习编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="TVM" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/TVM/"/>
    
    <category term="TVM介绍" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/TVM/TVM%E4%BB%8B%E7%BB%8D/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="编译器" scheme="http://example.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="TVM" scheme="http://example.com/tags/TVM/"/>
    
  </entry>
  
  <entry>
    <title>CUDA | CUDA的新竞争者</title>
    <link href="http://example.com/2024/07/19/CUDA%E7%9A%84%E6%96%B0%E7%AB%9E%E4%BA%89%E8%80%85/"/>
    <id>http://example.com/2024/07/19/CUDA%E7%9A%84%E6%96%B0%E7%AB%9E%E4%BA%89%E8%80%85/</id>
    <published>2024-07-19T15:23:07.000Z</published>
    <updated>2024-07-19T15:34:11.360Z</updated>
    
    <content type="html"><![CDATA[<p>AI时代，Nvidia作为HPC的头号玩家，其手中的主要利器有：高算力GPU、高速互联设备、CUDA，其中CUDA可以称之为Nvidia的护城河，只有使用CUDA才能利用Nvidia GPU进行高效的运行AI算法。</p><span id="more"></span><p>2024.7.12 英国公司Spectral Compute发布了<a href="[SCALE GPGPU Programming Language (scale-lang.com)](https://scale-lang.com/posts/2024-07-12-release-announcement)">SCALE BETA</a>，意图突破Nvidia的护城河-CUDA。SCALE是一个GPGPU工具链，它允许CUDA程序原生地运行在AMD GPUs上，后期也会提供其他厂商GPU的支持。SCALE的开发主要是为了让用户能够自由地使用GPGPU编程工具和GPU硬件，这些工具和硬件最好地满足了用户的开发需求。SCALE的横空出世，使得“Write once, run anywhere”对GPU来说称为可能。Spectral Compute公司计划通过跨越CUDA编程语言和其他厂商硬件之间的兼容性差距来实现“Write once, run anywhere”。</p><p>SCALE是一个类似于Nvidia CUDA工具的GPGPU工具，该工具能够将CUDA代码编译成面向非Nvidia GPUs的二进制代码。SCALE旨在与CUDA源代码兼容，包括支持内联PTX和NVCC的C++特性。</p><p>SCALE工具允许在其他厂商的GPU上运行CUDA code，打破必须使用与CUDA绑定的Nvidia硬件，这促进了AI算法开发以及部署的灵活度，可根据市场GPU的存量以及自身经济能力灵活的选择算力设备。</p><p>SCALE 文档：<a href="https://docs.scale-lang.com/examples/">SCALE Example Programs - SCALE documentation (scale-lang.com)</a></p><p>参考链接：<a href="https://mp.weixin.qq.com/s/y2M0bqTMzWC6F4sOkw2yHw">突破CUDA包围圈，再出一招</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;AI时代，Nvidia作为HPC的头号玩家，其手中的主要利器有：高算力GPU、高速互联设备、CUDA，其中CUDA可以称之为Nvidia的护城河，只有使用CUDA才能利用Nvidia GPU进行高效的运行AI算法。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI工具链" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/"/>
    
    <category term="CUDA" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/CUDA/"/>
    
    <category term="CUDA新的竞争者" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/CUDA/CUDA%E6%96%B0%E7%9A%84%E7%AB%9E%E4%BA%89%E8%80%85/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CUDA" scheme="http://example.com/tags/CUDA/"/>
    
    <category term="Nvidia" scheme="http://example.com/tags/Nvidia/"/>
    
    <category term="SCALE" scheme="http://example.com/tags/SCALE/"/>
    
    <category term="HPC" scheme="http://example.com/tags/HPC/"/>
    
  </entry>
  
  <entry>
    <title>AI基础设施 | 什么是智算中心</title>
    <link href="http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    <id>http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/</id>
    <published>2024-07-19T15:22:56.000Z</published>
    <updated>2024-07-19T15:37:22.379Z</updated>
    
    <content type="html"><![CDATA[<ol><li>三种数据中心<ul><li>通算中心（通用服务器-以CPU为主要芯片）</li><li>智算中心（智算服务器-以GPU/NPU/TPU等加速芯片为主）</li><li>超算中心（超级计算机）</li></ul></li></ol><span id="more"></span><ol start="2"><li><p>为什么要有智算中心？</p><ul><li><p>应用类型变化：传统应用以web应用为主，部署在以CPU为核心算力的通用服务器上。随着AI的快速发展，AI Native类型的应用快速占领市场，AI Native应用需要更多的算力。</p></li><li><p>传统服务器算力不足：大模型、其他AI算法的训练、推理过程需要更大的算力支撑，传统的通用服务器算力不能满足模型的训练和推理，因此需要构建拥有强大算力、高带宽通信的智算中心。</p></li></ul></li></ol><ol start="3"><li><p>什么是智算中心？</p><p><code>智算中心</code>由智算服务器组成，是以<code>人工智能</code>计算任务为主的<code>数据中心</code>。智算中心采用专门的AI算力硬件（<code>GPU</code>/<code>NPU</code>/<code>TPU</code>），适合高效运行AI算法，可以用于计算机视觉（Computer Vision）、自然语言处理（Natural Language Processing）、机器学习（Machine Learning）等领域，处理图像识别（Image Recognition）、语音识别（Speech Recognition）、文本分析（Text Analysis）、模型训练推理（Model Training and Inferring）等任务。</p></li></ol><ol start="4"><li><p>智算中心的核心-智算服务器：</p><ul><li><p>训练服务器（AI算力板卡多于推理服务器）：用于AI模型训练</p></li><li><p>推理服务器：用于AI算法推理</p></li><li><p>训推一体服务器：用于AI算法的训练和推理</p></li><li><p>算力大小：训练服务器 &gt;= 训推一体服务器 &gt; 推理服务器</p></li></ul></li></ol><p>参考链接：<a href="https://mp.weixin.qq.com/s/pbxWZvnRF1BMLQlwADxsNw">四问四答，彻底看懂智算中心！</a></p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;三种数据中心&lt;ul&gt;
&lt;li&gt;通算中心（通用服务器-以CPU为主要芯片）&lt;/li&gt;
&lt;li&gt;智算中心（智算服务器-以GPU/NPU/TPU等加速芯片为主）&lt;/li&gt;
&lt;li&gt;超算中心（超级计算机）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="智算中心" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    
    <category term="什么是智算中心？" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83%EF%BC%9F/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="智算中心" scheme="http://example.com/tags/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    
    <category term="智算服务器" scheme="http://example.com/tags/%E6%99%BA%E7%AE%97%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>VPN | 什么是VPN</title>
    <link href="http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AFVPN/"/>
    <id>http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AFVPN/</id>
    <published>2024-07-19T15:22:34.000Z</published>
    <updated>2024-07-19T15:30:56.892Z</updated>
    
    <content type="html"><![CDATA[<p>在工作、或学习中，如果连接的是内部网络，则可以直接访问内部网络资源，如果在家或出差时想要访问内部网络资源，常需要通过<code>VPN</code>才能访问公司/学校<code>内部网络资源</code>。那么VPN到底是什么呢？</p><span id="more"></span><p>VPN（Virtual Private Network）: 一种利用<code>公共网络</code>建立<code>专用网络</code>的技术。通过加密和隧道技术，VPN可以保护<code>数据传输的安全性和隐私性</code>，同时能够使<code>远程</code>用户安全访问企业/学校的内部网络资源。 </p><p>VPN的应用场景：</p><ol><li>远程工作</li><li>数据保护</li><li>隐私保护</li></ol><p>工作原理：</p><p>VPN通过创建一个加密的隧道来传输数据，确保数据在传输过程中的安全和隐私。VPN用户连接到VPN服务器后，所有网络流量都会被加密并通过隧道传输到VPN服务器，然后再解密和转发到互联网或内部网络</p><p><img src="/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AFVPN/VPN.png"></p><p>VPN分类以及区别：</p><ul><li>IPSec VPN(Internet Protocol Security VPN，互联网协议安全VPN)</li><li>SSL/TLS VPN（SSL-VPN,Secure Socket Layer, 安全套接层VPN）</li></ul><p>![](./什么是VPN/two types VPN.png)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在工作、或学习中，如果连接的是内部网络，则可以直接访问内部网络资源，如果在家或出差时想要访问内部网络资源，常需要通过&lt;code&gt;VPN&lt;/code&gt;才能访问公司/学校&lt;code&gt;内部网络资源&lt;/code&gt;。那么VPN到底是什么呢？&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VPN" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/"/>
    
    <category term="什么是VPN？" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/%E4%BB%80%E4%B9%88%E6%98%AFVPN%EF%BC%9F/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VPN" scheme="http://example.com/tags/VPN/"/>
    
    <category term="SSL VPN" scheme="http://example.com/tags/SSL-VPN/"/>
    
    <category term="IPsec VPN" scheme="http://example.com/tags/IPsec-VPN/"/>
    
  </entry>
  
  <entry>
    <title>TCP/IP | 秒懂TCPIP</title>
    <link href="http://example.com/2024/07/19/%E7%A7%92%E6%87%82TCPIP/"/>
    <id>http://example.com/2024/07/19/%E7%A7%92%E6%87%82TCPIP/</id>
    <published>2024-07-19T15:22:22.000Z</published>
    <updated>2024-07-19T15:25:13.411Z</updated>
    
    <content type="html"><![CDATA[<p>数据包传输过程中都用到了哪些协议？</p><p><a href="https://mp.weixin.qq.com/s/dysSZLyTRaSbr4650aQ7uA">全网介绍TCP/IP最全的文章</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;数据包传输过程中都用到了哪些协议？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/dysSZLyTRaSbr4650aQ7uA&quot;&gt;全网介绍TCP/IP最全的文章&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="TCP/IP" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-IP/"/>
    
    <category term="秒懂TCPIP" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-IP/%E7%A7%92%E6%87%82TCPIP/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="TCP/IP" scheme="http://example.com/tags/TCP-IP/"/>
    
    <category term="数据包" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%8C%85/"/>
    
    <category term="协议" scheme="http://example.com/tags/%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式训练集合通信以及集合通信原语</title>
    <link href="http://example.com/2024/07/17/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E4%BB%A5%E5%8F%8A%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/"/>
    <id>http://example.com/2024/07/17/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E4%BB%A5%E5%8F%8A%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/</id>
    <published>2024-07-17T12:09:13.000Z</published>
    <updated>2024-07-17T12:10:17.217Z</updated>
    
    <content type="html"><![CDATA[<p><code>大模型</code>的训练需要用到多个配有<code>GPU</code>的节点，GPU间通过<code>集合通信原语</code>进行通信，从而实现<code>GPU</code>间的<code>数据交换</code>和<code>共享</code>。</p><span id="more"></span><p><code>通信原语</code>的具体内容参考：<a href="https://zhuanlan.zhihu.com/p/493092647">分布式训练 – 第3篇 - 分布式训练常用的集合通信及其通信原语 - 知乎 (zhihu.com)</a>，这篇文章分析、总结的非常到位，此处不再额外总结。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;大模型&lt;/code&gt;的训练需要用到多个配有&lt;code&gt;GPU&lt;/code&gt;的节点，GPU间通过&lt;code&gt;集合通信原语&lt;/code&gt;进行通信，从而实现&lt;code&gt;GPU&lt;/code&gt;间的&lt;code&gt;数据交换&lt;/code&gt;和&lt;code&gt;共享&lt;/code&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="深度学习" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大模型" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="分布式训练" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"/>
    
    <category term="集合通信以及集合通信原语" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E4%BB%A5%E5%8F%8A%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/"/>
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="大模型" scheme="http://example.com/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="通信原语" scheme="http://example.com/tags/%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/"/>
    
    <category term="集合通信" scheme="http://example.com/tags/%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>CPU | CPU的组成以及功能</title>
    <link href="http://example.com/2024/07/16/CPU%E7%9A%84%E7%BB%84%E6%88%90%E4%BB%A5%E5%8F%8A%E5%8A%9F%E8%83%BD/"/>
    <id>http://example.com/2024/07/16/CPU%E7%9A%84%E7%BB%84%E6%88%90%E4%BB%A5%E5%8F%8A%E5%8A%9F%E8%83%BD/</id>
    <published>2024-07-16T12:12:08.000Z</published>
    <updated>2024-07-16T12:13:16.493Z</updated>
    
    <content type="html"><![CDATA[<p>回顾一下CPU的组成以及各组件的功能。</p><span id="more"></span><p><code>CPU</code>由<code>运算器</code>(arithmetic unit) 和<code>控制器</code>(controller)组成，运算器负责对数据进行加工处理(加减乘除等<code>算数运算</code>、与或非等<code>逻辑运算</code>)，控制器负责解析指令并向运算器或者存储器发出控制信号。</p><p><strong>运算器的组成及各部分的功能</strong>：</p><ul><li><p><code>乘商寄存器MQ</code>(Mulitple Quotient Register)：用于存放<code>乘、除法</code>运算时的操作数或运算结果</p></li><li><p><code>累加器ACC</code>(Accumulator)：用于存放<code>加、减法</code>运算的操作数或运算结果</p></li><li><p><code>算术逻辑单元ALU</code>(Arithmetic Logic Unit)：通过内部复杂的<code>电路实现算数运算、逻辑运算</code></p></li><li><p><code>通用寄存器X</code>：用于存放操作数</p></li><li><p>``程序状态字PSW<code>(Program State Word)：一个</code>特殊的寄存器<code>，用于存储CPU执行指令时的一些</code>重要状态信息<code>和</code>标志位<code>。PSW在指令执行过程中被不断地更新，以</code>反应当前指令执行的状态和结果`。</p><ul><li>PSW的重要标志位<ul><li>零标志位（ZF）：当运算结果为<code>0</code>时，ZF被置为1，否则为0</li><li>符号标志位（SF）：当运算结果为<code>负数</code>时，SF被置为1，否则为0</li><li>进位标志位（CF）：在<code>无符号加法和减法</code>中，当结果超出了所能表示的范围时，CF被置为1，否则为0</li><li>移除标志位（OF）：在<code>有符号加法和减法</code>中，当结果超出了所能表示的范围时，OF被置为1，否则为0</li><li>奇偶标志位（PF）：当运算结果中1的个数为偶数时，PF被置为1，否则为0</li></ul></li></ul></li><li><p>运算器中不同寄存器存放的操作数类型</p><table><thead><tr><th align="center"></th><th align="center">加</th><th align="center">减</th><th align="center">乘</th><th align="center">除</th></tr></thead><tbody><tr><td align="center">ACC</td><td align="center">被加数、和</td><td align="center">被减数、差</td><td align="center">乘积高位</td><td align="center">被除数、除数</td></tr><tr><td align="center">MQ</td><td align="center"></td><td align="center"></td><td align="center">乘数、乘积低位</td><td align="center">商</td></tr><tr><td align="center">X</td><td align="center">加数</td><td align="center">减数</td><td align="center">被乘数</td><td align="center">除数</td></tr></tbody></table></li></ul><p><strong>控制器的组成及各部分的功能</strong>：</p><ul><li>控制单元CU（Contorl Unit）：分析指令，给出控制信号</li><li>指令寄存器IR（Instruction Register）：存放当前执行指令</li><li>程序计数器PC（Program Counter）：存放指令地址，有自动加一功能</li></ul><p><strong>以计算加法运算“1+1”为例</strong>：</p><ol><li>CPU根据PC中的地址，将存储器中的指令“1+1”搬运到指令寄存器IR中（PC自动+1,指向下一条需要执行的指令）</li><li>CPU的CU对IR中的指令进行分析，将被加数1放入运算器的ACC中，将加数放入X中</li><li>CU控制ALU对ACC、X中的操作数进行运算，并将运算后的结果放入ACC中（此时PSW的一些标志位的值：ZF=0,SF=0,CF=0,PF=0）</li><li>CPU将ACC中的结果搬运到存储器中，完成本次运算</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;回顾一下CPU的组成以及各组件的功能。&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机组成原理" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    <category term="CPU" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/CPU/"/>
    
    <category term="CPU的组成以及各组件的功能" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/CPU/CPU%E7%9A%84%E7%BB%84%E6%88%90%E4%BB%A5%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E5%8A%9F%E8%83%BD/"/>
    
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="运算器" scheme="http://example.com/tags/%E8%BF%90%E7%AE%97%E5%99%A8/"/>
    
    <category term="CU" scheme="http://example.com/tags/CU/"/>
    
    <category term="控制器" scheme="http://example.com/tags/%E6%8E%A7%E5%88%B6%E5%99%A8/"/>
    
    <category term="controller" scheme="http://example.com/tags/controller/"/>
    
    <category term="算数运算" scheme="http://example.com/tags/%E7%AE%97%E6%95%B0%E8%BF%90%E7%AE%97/"/>
    
    <category term="逻辑运算" scheme="http://example.com/tags/%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>加速芯片 | 不同加速芯片的特点</title>
    <link href="http://example.com/2024/07/15/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/"/>
    <id>http://example.com/2024/07/15/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/</id>
    <published>2024-07-15T12:25:06.000Z</published>
    <updated>2024-07-15T12:34:00.345Z</updated>
    
    <content type="html"><![CDATA[<p>当前，<code>AI服务器</code>的芯片构成为”<code>CPU+加速芯片</code>“，加速芯片主要有<code>CPU</code>、<code>FPGA</code>和<code>ASIC</code>等加速芯片，利用CPU与加速芯片的组合可以满足高吞吐量互联的需求，从而加速模型的训练（training）、推理（Inference）过程。</p><span id="more"></span><p>CPU中有大量的<code>缓存</code>和复杂的<code>逻辑控制单元</code>，擅长<strong>逻辑控制、串行运算</strong>,但CPU的<strong>算力小</strong>，<strong>不擅长复杂算法运算和并行运算</strong>，因此在AI模型的训练过程中需要加速芯片来加速大量数据的计算，加速算法的演进和模型的更新。</p><p>CPU以及加速芯片（GPU、存算一体芯片）的架构：</p><p><img src="/2024/07/15/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/%E4%B8%8D%E5%90%8C%E8%8A%AF%E7%89%87%E7%9A%84%E6%9E%B6%E6%9E%84.png"></p><p>About 存算一体性芯片：大模型训练的过程是算法学习大数据中规律的过程，训练时间主要花费在<code>数据处理（学习）</code>和<code>数据搬运（在device和host之间搬运数据）</code>上，大模型的训练数据集往往非常庞大，<code>存算一体芯片</code>将计算单元需要的数据“放在自己身边”，减少芯片内外的数据搬运，从而提升了模型的训练效率。</p><p>不同AI加速芯片的优缺点：</p><table><thead><tr><th align="center">芯片类别（chips category）</th><th align="center">优点（advantages）</th><th align="center">缺点（disadvantages）</th><th align="center">产品</th></tr></thead><tbody><tr><td align="center">GPU</td><td align="center">支持大量<strong>并行计算</strong>（浮点运算能力）</td><td align="center"><strong>管理控制能力弱</strong>（CPU具备较强的管理控制能力），功耗高</td><td align="center">Nvidia A100、Nvidia H100等</td></tr><tr><td align="center">FPGA</td><td align="center">可重复编程、低延时、硬件可根据需求调整、<strong>灵活性最高</strong></td><td align="center">开发难度大、<strong>定点运算</strong>、价格贵</td><td align="center">Intel Arria 10等</td></tr><tr><td align="center">ASIC</td><td align="center">成本低、能耗低、性能强、<strong>针对AI设定特定架构</strong></td><td align="center">灵活性不够，价格高于FPGA</td><td align="center">谷歌TPU、华为昇腾910等</td></tr></tbody></table><p>参考链接：<a href="https://mp.weixin.qq.com/s/mkfVi3r9ehu67JpvlPG6_Q">AI 大模型算力芯片产业深度分析 2024</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;当前，&lt;code&gt;AI服务器&lt;/code&gt;的芯片构成为”&lt;code&gt;CPU+加速芯片&lt;/code&gt;“，加速芯片主要有&lt;code&gt;CPU&lt;/code&gt;、&lt;code&gt;FPGA&lt;/code&gt;和&lt;code&gt;ASIC&lt;/code&gt;等加速芯片，利用CPU与加速芯片的组合可以满足高吞吐量互联的需求，从而加速模型的训练（training）、推理（Inference）过程。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="不同加速芯片的特点" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/"/>
    
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="加速芯片" scheme="http://example.com/tags/%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87/"/>
    
    <category term="存算一体" scheme="http://example.com/tags/%E5%AD%98%E7%AE%97%E4%B8%80%E4%BD%93/"/>
    
    <category term="FPGA" scheme="http://example.com/tags/FPGA/"/>
    
    <category term="ASIC" scheme="http://example.com/tags/ASIC/"/>
    
  </entry>
  
  <entry>
    <title>CPU | 三条国产CPU发展路线</title>
    <link href="http://example.com/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/"/>
    <id>http://example.com/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/</id>
    <published>2024-07-15T12:20:28.000Z</published>
    <updated>2024-07-15T12:34:19.827Z</updated>
    
    <content type="html"><![CDATA[<p>三条国产CPU发展路线：</p><p><img src="/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/%E4%B8%8D%E5%90%8CCPU%E7%9A%84%E6%9E%B6%E6%9E%84.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;三条国产CPU发展路线：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/%E4%B8%8D%E5%90%8CC</summary>
      
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="CPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/"/>
    
    <category term="三条国产CPU发展路线" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="国产" scheme="http://example.com/tags/%E5%9B%BD%E4%BA%A7/"/>
    
    <category term="指令集" scheme="http://example.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="CISC" scheme="http://example.com/tags/CISC/"/>
    
    <category term="RISC" scheme="http://example.com/tags/RISC/"/>
    
    <category term="X86" scheme="http://example.com/tags/X86/"/>
    
    <category term="ARM" scheme="http://example.com/tags/ARM/"/>
    
    <category term="MIPS" scheme="http://example.com/tags/MIPS/"/>
    
    <category term="兆芯" scheme="http://example.com/tags/%E5%85%86%E8%8A%AF/"/>
    
    <category term="海光" scheme="http://example.com/tags/%E6%B5%B7%E5%85%89/"/>
    
    <category term="鲲鹏" scheme="http://example.com/tags/%E9%B2%B2%E9%B9%8F/"/>
    
    <category term="飞腾" scheme="http://example.com/tags/%E9%A3%9E%E8%85%BE/"/>
    
    <category term="龙芯" scheme="http://example.com/tags/%E9%BE%99%E8%8A%AF/"/>
    
    <category term="申威" scheme="http://example.com/tags/%E7%94%B3%E5%A8%81/"/>
    
  </entry>
  
  <entry>
    <title>高速互联 | PCIe与NVLink的对比</title>
    <link href="http://example.com/2024/07/15/PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    <id>http://example.com/2024/07/15/PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/</id>
    <published>2024-07-15T12:13:52.000Z</published>
    <updated>2024-07-15T12:34:33.070Z</updated>
    
    <content type="html"><![CDATA[<p><code>AI</code>算法极大程度上依赖于<code>大数据</code>（<code>Big Data</code>）,AI 算法的训练对机器的<code>算力</code>以及数据传输能力有着非常高的要求。算力问题的解决是通过提升<code>GPU</code>、<code>NPU</code>的计算能力，并且将多块<code>GPU/NPU</code>连接起来组成一个<code>算力网络</code>（Computing Force Network, <code>CFN</code>）。算力网络中的不同GPU/NPU需要进行互联，GPU/NPU也需要与CPU进行互联，从而共同协作完成大量数据的运算。</p><span id="more"></span><p>目前的<code>GPU互联方式</code>主要有两种：<code>PCIe</code>和<code>NVLink</code>，<strong>在同一个机器内，PCIe负责CPU与GPU之间的通信，NVlink负责GPU与GPU之间的通信。机器间的通信可通过TCP/IP网络协议或RDMA网络协议（InfiniBand、iWARP、RoCE）进行。</strong></p><p><img src="/2024/07/15/PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/NVLink.png"></p><ol><li><p>PCIe（PCI-Express）</p><ul><li><p>Peripheral Component Interconnect Express的简称，它是一种<code>内部总线</code>，也是一种<code>计算机扩展总线标准</code>，是一种<code>高速串行</code>、<code>高带宽</code>扩展总线，通常用于主板上连接<code>显卡</code>、<code>固态硬盘</code>以及采集卡和<code>无线网卡</code>等外设。</p></li><li><p>PCIe的两种存在形式：<code>M.2接口</code>和<code>PCIe标准插槽</code>。<code>加速卡</code>、<code>高带宽网卡</code>和<code>显卡</code>一般都是安装在<code>插槽</code>中。<code>固态硬盘</code>、<code>笔记本网卡</code>等一般使用<code>M.2接口</code>。</p></li><li><p>PCIe数据传输速率</p><table><thead><tr><th align="center">协议（Protocol）</th><th align="center">传输速率/Gbps</th></tr></thead><tbody><tr><td align="center">PCIe1.0</td><td align="center">2.5</td></tr><tr><td align="center">PCIe2.0</td><td align="center">5.0</td></tr><tr><td align="center">PCIe3.0</td><td align="center"><strong>8.0</strong></td></tr><tr><td align="center">PCIe4.0</td><td align="center">16</td></tr><tr><td align="center">PCIe5.0</td><td align="center">32</td></tr><tr><td align="center">PCIe6.0</td><td align="center">64</td></tr></tbody></table></li></ul></li><li><p>NVLink</p><ul><li><p><code>NVLink</code> 是一种<code>高速互连</code>技术，旨在加快 <code>CPU 与 GPU</code>、<code>GPU 与 GPU</code> 之间的数据传输速度，提高系统性能。</p></li><li><p>NVLink高速互联的两种形式：直连、NVSwitch。</p></li><li><p>NVLink数据传输速率</p><table><thead><tr><th align="center">协议（Protocol）</th><th align="center">发布时间</th><th align="center">显卡</th><th align="center">最大链数</th><th align="center">GPU之间总带宽</th><th align="center">应用架构</th></tr></thead><tbody><tr><td align="center">NVLink 1.0</td><td align="center">2016</td><td align="center">P100</td><td align="center">4</td><td align="center">160GB/s</td><td align="center">Pascal</td></tr><tr><td align="center">NVLink 2.0</td><td align="center">2017</td><td align="center">V100</td><td align="center">6</td><td align="center">300GB/s</td><td align="center">Volta</td></tr><tr><td align="center">NVLink 3.0</td><td align="center">2020</td><td align="center">A100</td><td align="center">12</td><td align="center">600GB/s</td><td align="center">Ampere</td></tr><tr><td align="center">NVLink 4.0</td><td align="center">2022</td><td align="center">H100</td><td align="center">18</td><td align="center">900GB/s</td><td align="center">Hopper</td></tr><tr><td align="center">NVLink 5.0</td><td align="center">2024</td><td align="center">GB200</td><td align="center">18</td><td align="center">1800GB/s</td><td align="center">Blackwell</td></tr></tbody></table></li></ul><p>![](./PCIe与NVLink的对比/NVLink Performance.png)</p></li><li><p>PCIe VS NVLink</p><p>![](./PCIe与NVLink的对比/PCIe VS NVLink.png)</p></li></ol><p>参考链接1：<a href="https://mp.weixin.qq.com/s/leRVFe9_ETxIOUvv3Wjecw">AI服务器内部“高速公路”：PCIe和NVLink技术！</a></p><p>参考链接2：<a href="https://www.nvidia.cn/data-center/nvlink/">NVLink 和 NVSwitch：卓越的 HPC 数据中心平台 | NVIDIA</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;AI&lt;/code&gt;算法极大程度上依赖于&lt;code&gt;大数据&lt;/code&gt;（&lt;code&gt;Big Data&lt;/code&gt;）,AI 算法的训练对机器的&lt;code&gt;算力&lt;/code&gt;以及数据传输能力有着非常高的要求。算力问题的解决是通过提升&lt;code&gt;GPU&lt;/code&gt;、&lt;code&gt;NPU&lt;/code&gt;的计算能力，并且将多块&lt;code&gt;GPU/NPU&lt;/code&gt;连接起来组成一个&lt;code&gt;算力网络&lt;/code&gt;（Computing Force Network, &lt;code&gt;CFN&lt;/code&gt;）。算力网络中的不同GPU/NPU需要进行互联，GPU/NPU也需要与CPU进行互联，从而共同协作完成大量数据的运算。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="GPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/"/>
    
    <category term="GPU高速互联-PCIe与NVLink的对比" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/GPU%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94-PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="高速互联" scheme="http://example.com/tags/%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94/"/>
    
    <category term="PCIe" scheme="http://example.com/tags/PCIe/"/>
    
    <category term="NVLink" scheme="http://example.com/tags/NVLink/"/>
    
    <category term="InfiniBand" scheme="http://example.com/tags/InfiniBand/"/>
    
    <category term="iWARP" scheme="http://example.com/tags/iWARP/"/>
    
    <category term="RoCE" scheme="http://example.com/tags/RoCE/"/>
    
    <category term="模型" scheme="http://example.com/tags/%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="CFN" scheme="http://example.com/tags/CFN/"/>
    
    <category term="NPU" scheme="http://example.com/tags/NPU/"/>
    
    <category term="NVSwitch" scheme="http://example.com/tags/NVSwitch/"/>
    
  </entry>
  
  <entry>
    <title>AI Native | 全新软件开发模式</title>
    <link href="http://example.com/2024/07/13/%E5%85%A8%E6%96%B0%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/"/>
    <id>http://example.com/2024/07/13/%E5%85%A8%E6%96%B0%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/</id>
    <published>2024-07-14T02:23:04.000Z</published>
    <updated>2024-07-14T02:26:01.128Z</updated>
    
    <content type="html"><![CDATA[<p><code>AI</code>的迅猛发展，对各行各业都带来了巨大的冲击，同时也带来了新的机会，催生了<code>AI+</code>的产业新模式，例如<code>AI+教育</code>、<code>AI+交通</code>、<code>AI+医疗</code>、<code>AI+农业</code>等，大量的AI+应用/项目已成熟落地。AI+应用的出现、普及改变了传统的<code>软件开发模式</code>，实现了focus on 软件到focus on 模型的转变。</p><span id="more"></span><p>软件是静态的代码数量，应用的价值与生产代码的数量成正比，主要靠人力scale；模型是动态的泛化智慧，应用价值与模型泛化能力成正比，靠数据scale。</p><p>传统软件依赖于提前制定的<code>规则</code>、约束，软件表现的能力依赖于软件产品设计者和开发者的能力。AI Native应用依赖于<code>模型</code>、<code>算法</code>的设计，而算法、模型又依赖于<code>大量的数据</code>，算法从大量的数据中学习并习得相应的能力，应用的能力不在约束于规则之内，像是拥有了某种<code>智能</code>。</p><p>市面上常见的三种主流AI产品类型包括<code>AI-by side</code>、<code>AI-Inside</code>和<code>AI-Based</code>。</p><ul><li><p>AI-by side</p><p>AI（算法、模型）在产品中是一个<code>可选项</code>，产品核心价值不受AI技术影响，即在用户使用产品时使用不使用AI能力都行，此时AI充当辅助的角色。例如，<code>Microsoft</code> 办公软件中的<code>AI copilot</code>功能。</p></li><li><p>AI-inside</p><p>AI在该类产品中是一个核心组件，称为影响产品价值的关键因素。例如市面上的<code>Gamma（AI展示工具）</code>应用，提供预先设计的模板，并为内容生成和设计元素添加人工智能，需要人工操作辅助+人工智能共同完成作品创作。在这个过程中，AI充当的是核心执行者，应用所依赖的算法的能力极大程度上影响着应用的核心价值。</p></li><li><p>AI-based</p><p>在该类产品中，AI是产品成立的基础，<code>没有AI就没有产品</code>，AI起到决定性的作用。例如市面上的<code>Tome（AI展示工具）</code>, 用户只需向应用提供想要生成的PPT的关键描述，应用即可按需完成任务，此过程中AI技术是该产品的基础。</p><p>AI-inside presentation tools Gamma 与AI-bassed presentation tools Tome的比较：<a href="https://slidespeak.co/blog/2024/01/03/tome-vs-gamma-comparing-two-ai-presentation-tools/">Tome vs Gamma：比较两种 AI 演示工具 - SlideSpeak</a></p></li></ul><p><img src="/2024/07/13/%E5%85%A8%E6%96%B0%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/%E4%B8%89%E7%A7%8D%E4%B8%BB%E6%B5%81AI%E4%BA%A7%E5%93%81%E7%B1%BB%E5%9E%8B.png"></p><p>具备了以上认知之后，再去认识<code>AI Native</code>就显得比较容易了，<code>AI Native</code>简单来说就是将AI技术集成到了软件中，并在软件中起到重要的作用，向用户提供智慧能力。这里也给出比较官方的解释：<code>AI Native</code>是一种基于人工智能技术的软件开发模式，它将<code>人工智能算法和模型</code>直接嵌入到应用程序中，使得应用程序具备<code>智能化</code>、<code>自动化</code>和<code>高效化</code>的能力。</p><p>对<code>AI Native</code>作一个简单总结：<code>AI Native</code>作为一种基于人工智能技术的软件开发模式，已经成为当今应用程序开发的重要趋势。未来，随着技术的不断进步和应用场景的不断拓展，<code>AI Native</code>将会在更多的领域得到应用和推广。对个人来说，应该在日常的work、study、life中提高AI Native应用的使用频率，通过AI Native应用的AI能力提高work、study的效率。</p><p><strong>参考文章：</strong></p><ol><li><a href="https://www.woshipm.com/ai/6044022.html">AI-Native 的大产品时代 | 人人都是产品经理 (woshipm.com)</a></li><li><a href="https://developer.baidu.com/article/details/3150909">AI Native工程化：百度App AI互动技术实践-百度开发者中心 (baidu.com)</a></li></ol><p>本文对AI Native的认识比较浅薄，想要深入认识AI Native，可以精读参考文章1，文章作者对于AI Native进行了独到的分析。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;AI&lt;/code&gt;的迅猛发展，对各行各业都带来了巨大的冲击，同时也带来了新的机会，催生了&lt;code&gt;AI+&lt;/code&gt;的产业新模式，例如&lt;code&gt;AI+教育&lt;/code&gt;、&lt;code&gt;AI+交通&lt;/code&gt;、&lt;code&gt;AI+医疗&lt;/code&gt;、&lt;code&gt;AI+农业&lt;/code&gt;等，大量的AI+应用/项目已成熟落地。AI+应用的出现、普及改变了传统的&lt;code&gt;软件开发模式&lt;/code&gt;，实现了focus on 软件到focus on 模型的转变。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI Native" scheme="http://example.com/categories/AI/AI-Native/"/>
    
    <category term="一种全新的软件开发模式-AI Native" scheme="http://example.com/categories/AI/AI-Native/%E4%B8%80%E7%A7%8D%E5%85%A8%E6%96%B0%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F-AI-Native/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="模型" scheme="http://example.com/tags/%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="软件开发模式" scheme="http://example.com/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%A8%A1%E5%BC%8F/"/>
    
    <category term="AI Native" scheme="http://example.com/tags/AI-Native/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络 | RDMA以及支持RDMA的网络协议</title>
    <link href="http://example.com/2024/07/13/RDMA%E4%BB%A5%E5%8F%8A%E6%94%AF%E6%8C%81RDMA%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    <id>http://example.com/2024/07/13/RDMA%E4%BB%A5%E5%8F%8A%E6%94%AF%E6%8C%81RDMA%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/</id>
    <published>2024-07-14T02:15:57.000Z</published>
    <updated>2024-07-14T02:20:11.008Z</updated>
    
    <content type="html"><![CDATA[<p><code>RDMA</code>(Remote Direct Memory Access)技术起初是为了缓解<code>CPU</code>的压力，提高CPU利用率，从而提高系统性能。随着<code>人工智能</code>（<code>AI</code>）、<code>AIGC</code>以及<code>大模型(LLM)</code>的快速发展，AI对于计算设备的<code>算力</code>以及数据处理能力有了更高的要求。</p><span id="more"></span><p>AI模型训练过程中需要反复、多次的在<code>host侧</code>（<code>CPU</code>）和<code>device侧</code>（<code>GPU</code>）之间进行大量数据的搬运，因此提升设备的数据搬运能够加快模型的训练。</p><p>传统的数据交换是通过<code>socket</code>进行通信，<code>socket</code>通信过程中，需要为<code>TCP</code>连接建立<code>socket</code>句柄，每次传输通信都要经过OS，因此数据传输效率不高。RDMA在每个服务器的网卡（Network Interface Card, <code>NIC</code>）中实现。通过绕过操作系统和网络内核，两台服务器之间的网络性能和数据交换会更快。<strong>传统socket通信类似于以红包的形式发压岁钱，需要长辈将钱先放入红包，然后晚辈收到红包之后，再拆开红包，才能获得红包中的钱。RDMA通信类似于如今比较流行的支付宝/微信转账方式，钱直接从一方到另一方，不需要“中转站”。</strong></p><p>![](./RDMA以及支持RDMA的网络协议/socket and rdma.png)</p><p><code>RDMA</code>具有<code>高带宽</code>、<code>低延迟</code>、<code>低CPU消耗</code>三种特点。</p><p>支持<code>RDMA</code>的三种网络协议：</p><ul><li><strong>InfiniBand(IB)</strong></li><li>RoCE(RDMA over converged Ethernet)<ul><li>RoCE v1</li><li><strong>RoCE v2</strong></li></ul></li><li>iWARP(RDMA over TCP/IP)</li></ul><p>![](./RDMA以及支持RDMA的网络协议/different protocol.png)</p><p>参考链接1：<a href="https://mp.weixin.qq.com/s/6_7RiyVr29bdc71dQcwmmw">AI 网络，为什么需要RDMA？</a></p><p>参考链接2：<a href="https://mp.weixin.qq.com/s/SG1iksSWI3N1WHx2ns4C4g">RoCE vs iWARP 十问十答</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;RDMA&lt;/code&gt;(Remote Direct Memory Access)技术起初是为了缓解&lt;code&gt;CPU&lt;/code&gt;的压力，提高CPU利用率，从而提高系统性能。随着&lt;code&gt;人工智能&lt;/code&gt;（&lt;code&gt;AI&lt;/code&gt;）、&lt;code&gt;AIGC&lt;/code&gt;以及&lt;code&gt;大模型(LLM)&lt;/code&gt;的快速发展，AI对于计算设备的&lt;code&gt;算力&lt;/code&gt;以及数据处理能力有了更高的要求。&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="RDMA" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RDMA/"/>
    
    <category term="RDMA以及支持RDMA的网络协议" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RDMA/RDMA%E4%BB%A5%E5%8F%8A%E6%94%AF%E6%8C%81RDMA%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="IB" scheme="http://example.com/tags/IB/"/>
    
    <category term="RDMA" scheme="http://example.com/tags/RDMA/"/>
    
    <category term="iWARP" scheme="http://example.com/tags/iWARP/"/>
    
    <category term="RoCE" scheme="http://example.com/tags/RoCE/"/>
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Some Ideas | 工作一周年快乐</title>
    <link href="http://example.com/2024/07/11/%E5%B7%A5%E4%BD%9C%E4%B8%80%E5%91%A8%E5%B9%B4%E5%BF%AB%E4%B9%90/"/>
    <id>http://example.com/2024/07/11/%E5%B7%A5%E4%BD%9C%E4%B8%80%E5%91%A8%E5%B9%B4%E5%BF%AB%E4%B9%90/</id>
    <published>2024-07-11T14:49:56.000Z</published>
    <updated>2024-07-11T15:00:02.134Z</updated>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="5890859dee33723eb5c58007ca4ce9ab1a4a6bee7fd88df744a8e44b1a6dfdc3">b780b0a90ab26cc39689a6bfa1e86daa85a23b37a0e6f2f4464173655f6ba4b2eefde371ceceadf186ce1a31c45b5b56644bd7ae01825ea010c2180ebb954e1b6cb449543c6047ee4bc0882e813dca83e197a4583afef7a6d6d9ce81ee5b8d4e20f0a9c86fbd01ca1ba0c318e330e1bbb53de828fb4744f53c754cf41037c1abb6edbbc74bcc6d6603b16a9393fa304ed2d94cba60300d57b8711af1910d9b2f</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">不公开，暂时保密哦！！！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <summary type="html">Here&#39;s something encrypted, password is required to continue reading.</summary>
    
    
    
    <category term="V Life" scheme="http://example.com/categories/V-Life/"/>
    
    <category term="Some Ideas" scheme="http://example.com/categories/V-Life/Some-Ideas/"/>
    
    <category term="victory, 工作一周年快乐！" scheme="http://example.com/categories/V-Life/Some-Ideas/victory-%E5%B7%A5%E4%BD%9C%E4%B8%80%E5%91%A8%E5%B9%B4%E5%BF%AB%E4%B9%90%EF%BC%81/"/>
    
    
    <category term="工作" scheme="http://example.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>Triton | 基于Triton语言实现的算子库FlagGems的环境配置以及测试</title>
    <link href="http://example.com/2024/07/11/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/"/>
    <id>http://example.com/2024/07/11/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/</id>
    <published>2024-07-11T13:54:23.000Z</published>
    <updated>2024-07-11T14:12:55.937Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>FlagGems介绍</p><p><code>FlagGems</code>是基于<code>OpenAI</code> <code>Triton</code>编程语言实现的<code>高性能通用算子库</code>，能够为<code>大语言模型</code>提供一系列可应用于<code>PyTorch</code>框架的算子，加速模型的<code>推理</code>与<code>训练</code>。</p><p>FlagGems通过对<code>PyTorch的后端aten算子进行覆盖重写</code>，实现算子库的无缝替换，使用户能够在不修改模型代码的情况下平稳地切换到triton算子库。FlagGems不会影响aten后端的正常使用。</p><p><img src="/2024/07/11/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/FlagGems%E5%AE%9E%E7%8E%B0.png"></p><p><strong>在pytorch中，核心的张量操作以及底层硬件通信是由ATen库实现的，当ATen需要执行一些可以在GPU上加速的操作时，它会通过CUDA来调用GPU的资源。具体来说，pytorch提供了易于使用的高层API,而ATen则提供张量计算和底层硬件通信。</strong></p></li></ul><span id="more"></span><ul><li><p>FlagGems的技术路线</p><p>FlagGems的技术路线选择的是统一开源算子库</p><p><img src="/2024/07/11/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF.png"></p></li><li><p>FlagGems Github仓库</p><p><a href="https://github.com/FlagOpen/FlagGems/blob/master/README_cn.md">FlagGems Github仓库</a></p></li><li><p>基础环境</p><ul><li>系统类型：<code>linux</code></li><li>CUDA version: 12.1</li></ul></li><li><p>FlagGems环境准备、搭建，环境搭建脚本如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> create virtual env.</span></span><br><span class="line">conda create -n flag-gems-test python==3.10</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> activate created virtual env.</span></span><br><span class="line">conda activate flag-gems-test</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> install pytorch <span class="keyword">in</span> virtual env.</span></span><br><span class="line">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> install pytest <span class="keyword">in</span> virtual env <span class="keyword">for</span> running <span class="built_in">test</span> code.</span></span><br><span class="line">pip install pytest</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">clone</span> <span class="string">&quot;FlagGems&quot;</span> from github repository.</span></span><br><span class="line">git clone https://github.com/FlagOpen/FlagGems.git</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> change directory to <span class="string">&quot;FlagGems/“.</span></span></span><br><span class="line">cd FlagGems</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string"> install &quot;</span>FlagGems<span class="string">&quot;.</span></span></span><br><span class="line">pip install .</span><br></pre></td></tr></table></figure></li><li><p>测试</p><ul><li><p>创建demo.py python文件并输入以下内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入pytorch</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 导入FlagGems</span></span><br><span class="line"><span class="keyword">import</span> flag_gems</span><br><span class="line"></span><br><span class="line">M, N, K = <span class="number">1024</span>, <span class="number">1024</span>, <span class="number">1024</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建M行K列的矩阵A</span></span><br><span class="line">A = torch.randn((M, K), dtype=torch.float16, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="comment"># 输出矩阵A</span></span><br><span class="line"><span class="built_in">print</span>(A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建K行N列的矩阵B</span></span><br><span class="line">B = torch.randn((K, N), dtype=torch.float16, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"><span class="comment"># 输出矩阵B</span></span><br><span class="line"><span class="built_in">print</span>(B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用FlagGems</span></span><br><span class="line"><span class="keyword">with</span> flag_gems.use_gems():</span><br><span class="line">    <span class="comment"># 矩阵乘法</span></span><br><span class="line">    C = torch.mm(A, B)</span><br><span class="line">    <span class="comment"># 输出矩阵乘法结果</span></span><br><span class="line">    <span class="built_in">print</span>(C)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>运行demo</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo.py</span><br></pre></td></tr></table></figure></li><li><p>运行结果</p><p><img src="/2024/07/11/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/result-of-mm.png"></p></li><li><p>算子以及模型正确性测试等参考github仓库介绍</p></li></ul></li></ul>]]></content>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;FlagGems介绍&lt;/p&gt;
&lt;p&gt;&lt;code&gt;FlagGems&lt;/code&gt;是基于&lt;code&gt;OpenAI&lt;/code&gt; &lt;code&gt;Triton&lt;/code&gt;编程语言实现的&lt;code&gt;高性能通用算子库&lt;/code&gt;，能够为&lt;code&gt;大语言模型&lt;/code&gt;提供一系列可应用于&lt;code&gt;PyTorch&lt;/code&gt;框架的算子，加速模型的&lt;code&gt;推理&lt;/code&gt;与&lt;code&gt;训练&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;FlagGems通过对&lt;code&gt;PyTorch的后端aten算子进行覆盖重写&lt;/code&gt;，实现算子库的无缝替换，使用户能够在不修改模型代码的情况下平稳地切换到triton算子库。FlagGems不会影响aten后端的正常使用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/07/11/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/FlagGems%E5%AE%9E%E7%8E%B0.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在pytorch中，核心的张量操作以及底层硬件通信是由ATen库实现的，当ATen需要执行一些可以在GPU上加速的操作时，它会通过CUDA来调用GPU的资源。具体来说，pytorch提供了易于使用的高层API,而ATen则提供张量计算和底层硬件通信。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI工具链" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/"/>
    
    <category term="Triton" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/Triton/"/>
    
    <category term="基于Triton语言实现的算子库FlagGems的环境配置以及测试" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/Triton/%E5%9F%BA%E4%BA%8ETriton%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%AE%97%E5%AD%90%E5%BA%93FlagGems%E7%9A%84%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8A%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="工具链" scheme="http://example.com/tags/%E5%B7%A5%E5%85%B7%E9%93%BE/"/>
    
    <category term="Triton" scheme="http://example.com/tags/Triton/"/>
    
    <category term="算子库" scheme="http://example.com/tags/%E7%AE%97%E5%AD%90%E5%BA%93/"/>
    
    <category term="FlagGems" scheme="http://example.com/tags/FlagGems/"/>
    
  </entry>
  
</feed>
