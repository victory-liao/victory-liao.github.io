<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Victory&#39;s Blog</title>
  
  <subtitle>非淡泊无以明志，非宁静无以致远</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-11-17T03:27:56.831Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>victory-liao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Computer Vision | 基于ResNet的CIFAER10图像分类</title>
    <link href="http://example.com/2021/11/16/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    <id>http://example.com/2021/11/16/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</id>
    <published>2021-11-17T03:26:33.000Z</published>
    <updated>2021-11-17T03:27:56.831Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于ResNet的CIFAER-10图像分类"><a href="#基于ResNet的CIFAER-10图像分类" class="headerlink" title="基于ResNet的CIFAER-10图像分类"></a>基于ResNet的CIFAER-10图像分类</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于ResNet的CIFAER-10图像分类&quot;&gt;&lt;a href=&quot;#基于ResNet的CIFAER-10图像分类&quot; class=&quot;headerlink&quot; title=&quot;基于ResNet的CIFAER-10图像分类&quot;&gt;&lt;/a&gt;基于ResNet的CIFAER-10图像</summary>
      
    
    
    
    <category term="项目经历" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/"/>
    
    <category term="Deep Learning" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/"/>
    
    <category term="Computer Vision" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/"/>
    
    <category term="基于ResNet的CIFAER-10图像分类" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER-10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
    
    <category term="基于ResNet的CIFAER-10图像分类" scheme="http://example.com/tags/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER-10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>Computer Vision | DogsVSCats</title>
    <link href="http://example.com/2021/11/16/DogsVSCats/"/>
    <id>http://example.com/2021/11/16/DogsVSCats/</id>
    <published>2021-11-17T02:34:35.000Z</published>
    <updated>2021-11-17T03:27:14.506Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dogs-VS-Cats"><a href="#Dogs-VS-Cats" class="headerlink" title="Dogs VS Cats"></a>Dogs VS Cats</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Dogs-VS-Cats&quot;&gt;&lt;a href=&quot;#Dogs-VS-Cats&quot; class=&quot;headerlink&quot; title=&quot;Dogs VS Cats&quot;&gt;&lt;/a&gt;Dogs VS Cats&lt;/h1&gt;</summary>
      
    
    
    
    <category term="项目经历" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/"/>
    
    <category term="Deep Learning" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/"/>
    
    <category term="Computer Vision" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/"/>
    
    <category term="Dogs VS Cats" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/Dogs-VS-Cats/"/>
    
    
    <category term="Dogs VS Cats" scheme="http://example.com/tags/Dogs-VS-Cats/"/>
    
  </entry>
  
  <entry>
    <title>脑电伪迹降噪方法整理</title>
    <link href="http://example.com/2021/11/15/%E8%84%91%E7%94%B5%E4%BC%AA%E8%BF%B9%E9%99%8D%E5%99%AA%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
    <id>http://example.com/2021/11/15/%E8%84%91%E7%94%B5%E4%BC%AA%E8%BF%B9%E9%99%8D%E5%99%AA%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/</id>
    <published>2021-11-15T13:31:27.000Z</published>
    <updated>2021-11-15T13:33:18.619Z</updated>
    
    <content type="html"><![CDATA[<h1 id="脑电伪迹降噪方法整理"><a href="#脑电伪迹降噪方法整理" class="headerlink" title="脑电伪迹降噪方法整理"></a>脑电伪迹降噪方法整理</h1><p><a href="https://mp.weixin.qq.com/s/gRIP-fuYsZv2p92qptOmew">脑电伪迹降噪方法整理</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;脑电伪迹降噪方法整理&quot;&gt;&lt;a href=&quot;#脑电伪迹降噪方法整理&quot; class=&quot;headerlink&quot; title=&quot;脑电伪迹降噪方法整理&quot;&gt;&lt;/a&gt;脑电伪迹降噪方法整理&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/gR</summary>
      
    
    
    
    <category term="Research and Paper" scheme="http://example.com/categories/Research-and-Paper/"/>
    
    <category term="EEG" scheme="http://example.com/categories/Research-and-Paper/EEG/"/>
    
    <category term="伪迹移除" scheme="http://example.com/categories/Research-and-Paper/EEG/%E4%BC%AA%E8%BF%B9%E7%A7%BB%E9%99%A4/"/>
    
    <category term="脑电伪迹降噪方法整理" scheme="http://example.com/categories/Research-and-Paper/EEG/%E4%BC%AA%E8%BF%B9%E7%A7%BB%E9%99%A4/%E8%84%91%E7%94%B5%E4%BC%AA%E8%BF%B9%E9%99%8D%E5%99%AA%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
    
    
    <category term="伪迹移除" scheme="http://example.com/tags/%E4%BC%AA%E8%BF%B9%E7%A7%BB%E9%99%A4/"/>
    
    <category term="EEG" scheme="http://example.com/tags/EEG/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 | 模型存储的5种方法</title>
    <link href="http://example.com/2021/11/15/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8%E7%9A%845%E4%B8%AD%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2021/11/15/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8%E7%9A%845%E4%B8%AD%E6%96%B9%E6%B3%95/</id>
    <published>2021-11-15T13:01:09.000Z</published>
    <updated>2021-11-15T13:06:48.166Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型存储的5种方法"><a href="#模型存储的5种方法" class="headerlink" title="模型存储的5种方法"></a>模型存储的5种方法</h1><p><strong>方法1：csv/txt</strong><br>存储为csv、text或者json是最为简单的存储格式，阅读和解析起来非常方便。<br>如果使用Pandas则可以在存储的过程中设置压缩方法，对磁盘比较友好。</p><p><strong>·</strong> 场景：通用<br><strong>·</strong> 数据：表格、文本<br><strong>·</strong> 文件大小：压缩后较少<br><strong>·</strong> 读取速度：较慢</p><pre><code>compression_opts = dict(method=&#39;zip&#39;,                        archive_name=&#39;out.csv&#39;)  df.to_csv(&#39;out.zip&#39;, index=False,          compression=compression_opts) </code></pre><p><strong>方法2：hdf</strong><br>HDF(Hierarchical Data File)是能满足各种领域研究需求而研制的一种能高效存储和分发科学数据的新型数据格式。<br>HDF格式支持分层存储，可以将多个变量同时存在一个HDF文件中，同时在读取速度上也比较快。</p><p><strong>·</strong> 场景：通用<br><strong>·</strong> 数据：表格、文本<br><strong>·</strong> 文件大小：较大<br><strong>·</strong> 读取速度：较快</p><pre><code>df = pd.DataFrame(&#123;&#39;A&#39;: [1, 2, 3], &#39;B&#39;: [4, 5, 6]&#125;,                  index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])df.to_hdf(&#39;data.h5&#39;, key=&#39;df&#39;, mode=&#39;w&#39;)</code></pre><p><strong>方法3：npy</strong><br>如果将特征和数据处理为Numpy格式，则可以考虑存储为Numpy中的npy或npz格式。</p><p><strong>·</strong> 场景：文件存储<br><strong>·</strong> 数据：矩阵<br><strong>·</strong> 文件大小：适中<br><strong>·</strong> 读取速度：较快</p><ol><li>npy文件：二进制格式<br>np.load()和np.save()是读写磁盘数组数据的两个重要函数。使用时数组会以未压缩的原始二进制格式保存在扩展名为.npy的文件中。</li></ol><pre><code>import numpy as nparr=np.arange(5)np.save(&#39;test&#39;,arr)print(np.load(&#39;test.npy&#39;))</code></pre><p>2.npz文件：压缩文件<br>使用np.savez()函数可以将多个数组保存到同一个文件中。读取.npz文件时使用np.load()函数，返回的是一个类似于字典的对象，因此可以通过数组名作为关键字对多个数组进行访问。</p><pre><code>import numpy as npa = np.arange(5)b = np.arange(6)c = np.arange(7)np.savez(&#39;test&#39;, a, b, c_array=c)  # c_array是数组c的命名data = np.load(&#39;test.npz&#39;)print(&#39;arr_0 : &#39;, data[&#39;arr_0&#39;])print(&#39;arr_1 : &#39;, data[&#39;arr_1&#39;])print(&#39;c_array : &#39;, data[&#39;c_array&#39;])</code></pre><p><strong>方法4：memmap</strong><br>NumPy实现了一个类似于ndarray的memmap对象，它允许将大文件分成小段进行读写，而不是一次性将整个数组读入内存。</p><p>如果需要存储的对象大于内存，则可以选择memmap进行存储。</p><p><strong>·</strong> 场景：大文件存储<br><strong>·</strong> 数据：矩阵<br><strong>·</strong> 文件大小：较大、特别大<br><strong>·</strong> 读取速度：适中</p><pre><code>newfp = np.memmap(filename, dtype=&#39;float32&#39;, mode=&#39;r&#39;, shape=(3,4))fpc[0,:] = 0</code></pre><p><strong>方法5：joblib</strong><br>类似于pkl存储，joblib.dump可以将任意的Python对象持久化到一个文件中，并使用joblib.load进行读取。</p><p><strong>·</strong> 场景：任意<br><strong>·</strong> 数据：任意<br><strong>·</strong> 文件大小：适中<br><strong>·</strong> 读取速度：适中</p><pre><code>from joblib import load, dumpX = [[0, 0], [1, 1]]Y = [1, 0]dump((X, Y), &quot;data.pkl&quot;)X, Y = load(&quot;data.pkl&quot;)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;模型存储的5种方法&quot;&gt;&lt;a href=&quot;#模型存储的5种方法&quot; class=&quot;headerlink&quot; title=&quot;模型存储的5种方法&quot;&gt;&lt;/a&gt;模型存储的5种方法&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;方法1：csv/txt&lt;/strong&gt;&lt;br&gt;存储为csv、tex</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="模型存储" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="模型存储" scheme="http://example.com/tags/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 卷积神经网络之卷积计算作用与思想</title>
    <link href="http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E4%BD%9C%E7%94%A8%E4%B8%8E%E6%80%9D%E6%83%B3/"/>
    <id>http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E4%BD%9C%E7%94%A8%E4%B8%8E%E6%80%9D%E6%83%B3/</id>
    <published>2021-11-15T12:57:16.000Z</published>
    <updated>2021-11-15T12:58:41.489Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络之卷积计算作用与思想"><a href="#卷积神经网络之卷积计算作用与思想" class="headerlink" title="卷积神经网络之卷积计算作用与思想"></a>卷积神经网络之卷积计算作用与思想</h1><p><a href="https://www.cnblogs.com/shine-lee/p/9932226.html">卷积神经网络之卷积计算、作用与思想</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;卷积神经网络之卷积计算作用与思想&quot;&gt;&lt;a href=&quot;#卷积神经网络之卷积计算作用与思想&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络之卷积计算作用与思想&quot;&gt;&lt;/a&gt;卷积神经网络之卷积计算作用与思想&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="卷积" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/%E5%8D%B7%E7%A7%AF/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="卷积" scheme="http://example.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 卷积和卷积核</title>
    <link href="http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8/"/>
    <id>http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8/</id>
    <published>2021-11-15T12:29:06.000Z</published>
    <updated>2021-11-15T12:31:58.186Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积和卷积核"><a href="#卷积和卷积核" class="headerlink" title="卷积和卷积核"></a>卷积和卷积核</h1><p>1.卷积<br>原理:卷积过程就是卷积核行列对称翻转后,在图像上滑动,并且依次相乘求和.(与滤波器不同的一点就是多了一个卷积核翻转的过程).然后经过池化,激活后输入下一层.<br>单个卷积层可以提取特征,当多个卷积叠加后即可逐步学习出更高语义的抽象特征.<br>2.卷积核<br>卷积核:其中卷积核主要有两类,普通卷积核和1<em>1的卷积核.普通卷积核同时改变图像的空间域和通道域,如下图所示,每个卷积核的通道数与输入相同,<br>卷积后会得到一个通道为一的特征图,我们希望卷积后的通道数有几个,卷积核就有几个.<br>1</em>1卷积核,视野大小为单个特征位点,能够实现在空间域不改变的情况下实现通道域信息的交流,<br>并且获得我们想要的通道数量(一般是降维).</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;卷积和卷积核&quot;&gt;&lt;a href=&quot;#卷积和卷积核&quot; class=&quot;headerlink&quot; title=&quot;卷积和卷积核&quot;&gt;&lt;/a&gt;卷积和卷积核&lt;/h1&gt;&lt;p&gt;1.卷积&lt;br&gt;原理:卷积过程就是卷积核行列对称翻转后,在图像上滑动,并且依次相乘求和.(与滤波器不同的一点</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="卷积" scheme="http://example.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
    <category term="卷积核" scheme="http://example.com/tags/%E5%8D%B7%E7%A7%AF%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>VGG | 使用3x3卷积核的优点</title>
    <link href="http://example.com/2021/11/15/VGG3x3%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%BC%98%E7%82%B9/"/>
    <id>http://example.com/2021/11/15/VGG3x3%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%BC%98%E7%82%B9/</id>
    <published>2021-11-15T12:24:44.000Z</published>
    <updated>2021-11-15T12:26:22.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="VGG使用3x3卷积核的优点"><a href="#VGG使用3x3卷积核的优点" class="headerlink" title="VGG使用3x3卷积核的优点"></a>VGG使用3x3卷积核的优点</h1><p>2个3x3的卷积核串联和一个5x5的卷积核拥有相同的感受野，但是，2个3x3的卷积核拥有更少的参数，<br>对于通道为1的5x5特征图得到通道为1的输出特征图，前者有3x3x2=18个参数，后者5x5=25个参数，<br>其次，多个3x3的卷积核比一个较大的尺寸的卷积核加入了更多的非线性函数，增强了模型的非线性表达能力。<br><strong>1x1卷积核的作用：</strong> 改变通道数目，保持尺度不变情况下增强非线性表达能力，可以实现跨通道的信息交互。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;VGG使用3x3卷积核的优点&quot;&gt;&lt;a href=&quot;#VGG使用3x3卷积核的优点&quot; class=&quot;headerlink&quot; title=&quot;VGG使用3x3卷积核的优点&quot;&gt;&lt;/a&gt;VGG使用3x3卷积核的优点&lt;/h1&gt;&lt;p&gt;2个3x3的卷积核串联和一个5x5的卷积核拥</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="VGG" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/VGG/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="VGG" scheme="http://example.com/tags/VGG/"/>
    
  </entry>
  
  <entry>
    <title>CNN | BatchNormalization</title>
    <link href="http://example.com/2021/11/15/BatchNormalization/"/>
    <id>http://example.com/2021/11/15/BatchNormalization/</id>
    <published>2021-11-15T12:22:11.000Z</published>
    <updated>2021-11-15T12:23:39.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="BatchNormalization"><a href="#BatchNormalization" class="headerlink" title="BatchNormalization"></a>BatchNormalization</h1><p>由于深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，<br>通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。<br>为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。<br>也就是随是着网络加深，参数分布不断往激活函数两端移动(梯度变小)，导致反向传播出现梯度消失，收敛困难。<br>原理：可在每层的激活函数前，加入BN，将参数重新拉回0-1正态分布，加速收敛。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;BatchNormalization&quot;&gt;&lt;a href=&quot;#BatchNormalization&quot; class=&quot;headerlink&quot; title=&quot;BatchNormalization&quot;&gt;&lt;/a&gt;BatchNormalization&lt;/h1&gt;&lt;p&gt;由于深度神经</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="Batch Normalization" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/Batch-Normalization/"/>
    
    
    <category term="Batch Normalization" scheme="http://example.com/tags/Batch-Normalization/"/>
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>numpy | shuffle数据</title>
    <link href="http://example.com/2021/11/15/shuffle%E6%95%B0%E6%8D%AE/"/>
    <id>http://example.com/2021/11/15/shuffle%E6%95%B0%E6%8D%AE/</id>
    <published>2021-11-15T12:14:50.000Z</published>
    <updated>2021-11-15T12:17:53.666Z</updated>
    
    <content type="html"><![CDATA[<h1 id="shuffle数据"><a href="#shuffle数据" class="headerlink" title="shuffle数据"></a>shuffle数据</h1><p>在使用大量的数据来训练深度学习模型时，我们有可能需要对训练数据和数据标签进行shuffle(打乱)操作。</p><span id="more"></span><p><strong>show you the example code:</strong></p><pre><code>data = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])y = np.array([1, 2, 3, 4, 5])print(&#39;-------原数据：----------&#39;)print(&#39;数据：&#39;, data)print(&#39;标签：&#39;, y)print(&#39;-------打乱数据：----------&#39;)np.random.seed(116)np.random.shuffle(data)np.random.seed(116)np.random.shuffle(y)print(&#39;数据：&#39;, data)print(&#39;标签：&#39;, y )</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;shuffle数据&quot;&gt;&lt;a href=&quot;#shuffle数据&quot; class=&quot;headerlink&quot; title=&quot;shuffle数据&quot;&gt;&lt;/a&gt;shuffle数据&lt;/h1&gt;&lt;p&gt;在使用大量的数据来训练深度学习模型时，我们有可能需要对训练数据和数据标签进行shuffle(打乱)操作。&lt;/p&gt;</summary>
    
    
    
    <category term="python" scheme="http://example.com/categories/python/"/>
    
    <category term="第三方库" scheme="http://example.com/categories/python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"/>
    
    <category term="numpy" scheme="http://example.com/categories/python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/numpy/"/>
    
    
    <category term="numpy" scheme="http://example.com/tags/numpy/"/>
    
    <category term="shuffle" scheme="http://example.com/tags/shuffle/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 | 深度学习基础问题</title>
    <link href="http://example.com/2021/11/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2021/11/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98/</id>
    <published>2021-11-15T04:31:53.000Z</published>
    <updated>2021-11-15T04:33:04.457Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习基础问题"><a href="#深度学习基础问题" class="headerlink" title="深度学习基础问题"></a>深度学习基础问题</h1><p><a href="https://mp.weixin.qq.com/s/KcIlkLyNROxC_TUbCDhEmg">深度学习基础问题</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;深度学习基础问题&quot;&gt;&lt;a href=&quot;#深度学习基础问题&quot; class=&quot;headerlink&quot; title=&quot;深度学习基础问题&quot;&gt;&lt;/a&gt;深度学习基础问题&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/KcIlkLyNRO</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 卷积的三种模式</title>
    <link href="http://example.com/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"/>
    <id>http://example.com/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/</id>
    <published>2021-11-15T04:21:19.000Z</published>
    <updated>2021-11-15T04:27:26.593Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积的三种模式"><a href="#卷积的三种模式" class="headerlink" title="卷积的三种模式"></a>卷积的三种模式</h1><p>通常用外部api进行卷积的时候，会面临mode选择<br>其实这三种不同模式是对卷积核移动范围的不同限制<br>设 image的大小是7x7，filter的大小是3x3</p><span id="more"></span><p><strong>full mode:</strong><br>橙色部分为image, 蓝色部分为filter。full模式的意思是，从filter和image刚相交开始做卷积，白色部分为填0。filter的运动范围如图所示。<br><img src="/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/1.jpg"><br><strong>same mode:</strong><br>当filter的中心(K)与image的边角重合时，开始做卷积运算，可见filter的运动范围比full模式小了一圈。注意：这里的same还有一个意思，卷积之后输出的feature map尺寸保持不变(相对于输入图片)。当然，same模式不代表完全输入输出尺寸一样，也跟卷积核的步长有关系。same模式也是最常见的模式，因为这种模式可以在前向传播的过程中让特征图的大小保持不变，调参师不需要精准计算其尺寸变化(因为尺寸根本就没变化)。<br><img src="/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/2.jpg"><br><strong>valid mode:</strong><br>当filter全部在image里面的时候，进行卷积运算，可见filter的移动范围较same更小了。<br><img src="/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/3.jpg"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;卷积的三种模式&quot;&gt;&lt;a href=&quot;#卷积的三种模式&quot; class=&quot;headerlink&quot; title=&quot;卷积的三种模式&quot;&gt;&lt;/a&gt;卷积的三种模式&lt;/h1&gt;&lt;p&gt;通常用外部api进行卷积的时候，会面临mode选择&lt;br&gt;其实这三种不同模式是对卷积核移动范围的不同限制&lt;br&gt;设 image的大小是7x7，filter的大小是3x3&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="卷积的三种模式" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="valid" scheme="http://example.com/tags/valid/"/>
    
    <category term="same" scheme="http://example.com/tags/same/"/>
    
    <category term="full" scheme="http://example.com/tags/full/"/>
    
  </entry>
  
  <entry>
    <title>python | 垃圾回收机制</title>
    <link href="http://example.com/2021/11/14/python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2021/11/14/python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/</id>
    <published>2021-11-15T02:59:35.000Z</published>
    <updated>2021-11-15T03:11:27.550Z</updated>
    
    <content type="html"><![CDATA[<h1 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="垃圾回收机制"></a>垃圾回收机制</h1><h2 id="Pyhton垃圾回收机制"><a href="#Pyhton垃圾回收机制" class="headerlink" title="Pyhton垃圾回收机制"></a>Pyhton垃圾回收机制</h2><p>1.引用计数<br><strong>引用计数法的原理是：</strong> 每个对象维护一个ob_ref字段，用来记录该对象当前被引用的次数，每当新的引用指向该对象时，它的引用计数ob_ref加1，每当该对象的引用失效时计数ob_ref减1，一旦对象的引用计数为0，该对象立即被回收，对象占用的内存空间将被释放。<br><strong>缺点：</strong> 无法解决循环引用<br>2.标记清除<br>Python采用了“标记-清除”(Mark and Sweep)算法，解决容器对象可能产生的循环引用问题。<br><strong>标记阶段</strong> 遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达；<br><strong>清除阶段</strong> 再次遍历对象，如果发现某个对象没有标记为可达，则就将其回收。<br><strong>优点：</strong> 解决了循环引用问题<br><strong>缺点：</strong> 标记清除算法在执行很多次数后，程序的堆空间会产生一些小的内存碎片。<br>3.分代回收(假设新生代、中生代和老生代的threshold分别为700、10、10.)<br>· 每新增 701 个需要 GC 的对象，触发一次新生代 GC<br>· 每执行 11 次新生代 GC ，触发一次中生代 GC<br>· 每执行 11 次中生代 GC ，触发一次老生代 GC (老生代 GC 还受其他策略影响，频率更低)<br>· 执行某个生代 GC 前，年轻生代对象链表也移入该代，一起 GC<br>· 一个对象创建后，随着时间推移将被逐步移入老生代，回收频率逐渐降低</p><p><a href="https://mp.weixin.qq.com/s/y_pqtoB-FcTxwBOHpi8hAg">参考资料</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;垃圾回收机制&quot;&gt;&lt;a href=&quot;#垃圾回收机制&quot; class=&quot;headerlink&quot; title=&quot;垃圾回收机制&quot;&gt;&lt;/a&gt;垃圾回收机制&lt;/h1&gt;&lt;h2 id=&quot;Pyhton垃圾回收机制&quot;&gt;&lt;a href=&quot;#Pyhton垃圾回收机制&quot; class=&quot;head</summary>
      
    
    
    
    <category term="python" scheme="http://example.com/categories/python/"/>
    
    <category term="基础" scheme="http://example.com/categories/python/%E5%9F%BA%E7%A1%80/"/>
    
    <category term="gc" scheme="http://example.com/categories/python/%E5%9F%BA%E7%A1%80/gc/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="垃圾回收机制" scheme="http://example.com/tags/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/"/>
    
    <category term="gc" scheme="http://example.com/tags/gc/"/>
    
  </entry>
  
  <entry>
    <title>参考文献 | Identifying Users and Activities with Cognitive Signal Processing from a Wearable Headband</title>
    <link href="http://example.com/2021/11/13/IdentifyingUsersAndActivitiesWithCognitiveSignalProcessingFromAWearableHeadband/"/>
    <id>http://example.com/2021/11/13/IdentifyingUsersAndActivitiesWithCognitiveSignalProcessingFromAWearableHeadband/</id>
    <published>2021-11-14T07:58:13.000Z</published>
    <updated>2021-11-14T09:28:35.712Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Identifying-Users-and-Activities-with-Cognitive-Signal-Processing-from-a-Wearable-Headband"><a href="#Identifying-Users-and-Activities-with-Cognitive-Signal-Processing-from-a-Wearable-Headband" class="headerlink" title="Identifying Users and Activities with Cognitive Signal Processing from a Wearable Headband"></a>Identifying Users and Activities with Cognitive Signal Processing from a Wearable Headband</h1><h2 id="Predictions"><a href="#Predictions" class="headerlink" title="Predictions"></a>Predictions</h2><p>1.Predicting a person<br>2.Predicting an activity<br>3.Predicting a person as well as the activity</p><h2 id="Contributions-propose-a-method-of-data-representation-histograms-representation"><a href="#Contributions-propose-a-method-of-data-representation-histograms-representation" class="headerlink" title="Contributions: propose a method of data representation-histograms representation"></a>Contributions: propose a method of data representation-histograms representation</h2><p>This paper shows that <strong>histograms of brain signals</strong> can be a very useful representation for data mining<br>activities. One of the primary advantages of the histograms is that they <strong>reduce the variable length<br>of signals to fixed length representations</strong>.</p><h2 id="ideas-from-reading-this-paper"><a href="#ideas-from-reading-this-paper" class="headerlink" title="ideas from reading this paper"></a>ideas from reading this paper</h2><p>combining activities predicting/emotion recognition to a system.</p><h2 id="Cite-this-paper"><a href="#Cite-this-paper" class="headerlink" title="Cite this paper"></a>Cite this paper</h2><p>Wiechert, Glavin &amp; Triff, Matt &amp; Liu, Zhixing &amp; Yin, Zhicheng &amp; Zhao, Shuai &amp; Zhong, Ziyun &amp; Zhaou, Runxing &amp; Lingras, Pawan. (2016). Identifying users and activities with cognitive signal processing from a wearable headband. 129-136. 10.1109/ICCI-CC.2016.7862025. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Identifying-Users-and-Activities-with-Cognitive-Signal-Processing-from-a-Wearable-Headband&quot;&gt;&lt;a href=&quot;#Identifying-Users-and-Activiti</summary>
      
    
    
    
    <category term="Rsearch and Paper" scheme="http://example.com/categories/Rsearch-and-Paper/"/>
    
    <category term="EEG" scheme="http://example.com/categories/Rsearch-and-Paper/EEG/"/>
    
    <category term="脑电分类" scheme="http://example.com/categories/Rsearch-and-Paper/EEG/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/"/>
    
    <category term="参考文献" scheme="http://example.com/categories/Rsearch-and-Paper/EEG/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/"/>
    
    
    <category term="脑电分类" scheme="http://example.com/tags/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/"/>
    
    <category term="EEG" scheme="http://example.com/tags/EEG/"/>
    
  </entry>
  
  <entry>
    <title>python | 去除字符串首尾空格</title>
    <link href="http://example.com/2021/11/13/python%E5%8E%BB%E9%99%A4%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%A6%96%E5%B0%BE%E7%A9%BA%E6%A0%BC/"/>
    <id>http://example.com/2021/11/13/python%E5%8E%BB%E9%99%A4%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%A6%96%E5%B0%BE%E7%A9%BA%E6%A0%BC/</id>
    <published>2021-11-14T02:30:36.000Z</published>
    <updated>2021-11-14T02:50:16.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="去除字符串首尾空格"><a href="#去除字符串首尾空格" class="headerlink" title="去除字符串首尾空格"></a>去除字符串首尾空格</h1><p>程序使用两种方法去除字符串首尾的空格。</p><span id="more"></span><h2 id="1-strip-rstrip-lstrip"><a href="#1-strip-rstrip-lstrip" class="headerlink" title="1.strip() rstrip() lstrip()"></a>1.strip() rstrip() lstrip()</h2><pre><code>a = &#39;  welcome to my world  &#39;print(len(a))print(len(a.strip()))  # 去掉首尾字符串print(len(a.lstrip()))  # 去掉首部空格print(len(a.rstrip()))  # 去掉尾部空格print(len(a.lstrip().rstrip()))  # 先去掉首部空格再去掉尾部空格</code></pre><h1 id="2-递归实现"><a href="#2-递归实现" class="headerlink" title="2.递归实现"></a>2.递归实现</h1><pre><code>def trim(s):    flag = 0    if s[:1] == &#39; &#39;:        s = s[1:]        flag = 1    if s[-1:] == &#39; &#39;:        s = s[:-1]        flag = 1    if flag == 1:        return trim(s)    else:        return sprint(len(&#39;  Hello World  &#39;))  # 15print(len(trim(&#39;  Hello World  &#39;)))  # 11</code></pre><h1 id="3-while循环实现"><a href="#3-while循环实现" class="headerlink" title="3.while循环实现"></a>3.while循环实现</h1><pre><code>def trim(s):    while True:        flag = 0        if s[:1] == &#39; &#39;:            s = s[1:]            flag = 1        if s[-1:] == &#39; &#39;:            s = s[:-1]            flag = 1        if flag == 0:            break    return sprint(len(&#39;  Hello World  &#39;))  # 15print(len(trim(&#39;  Hello World  &#39;)))  # 11</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;去除字符串首尾空格&quot;&gt;&lt;a href=&quot;#去除字符串首尾空格&quot; class=&quot;headerlink&quot; title=&quot;去除字符串首尾空格&quot;&gt;&lt;/a&gt;去除字符串首尾空格&lt;/h1&gt;&lt;p&gt;程序使用两种方法去除字符串首尾的空格。&lt;/p&gt;</summary>
    
    
    
    <category term="python" scheme="http://example.com/categories/python/"/>
    
    <category term="基础" scheme="http://example.com/categories/python/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="strip" scheme="http://example.com/tags/strip/"/>
    
  </entry>
  
  <entry>
    <title>RNN | LSTM</title>
    <link href="http://example.com/2021/11/13/LSTM/"/>
    <id>http://example.com/2021/11/13/LSTM/</id>
    <published>2021-11-14T02:25:29.000Z</published>
    <updated>2021-11-14T02:27:54.039Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Understanding-LSTM-Networks"><a href="#Understanding-LSTM-Networks" class="headerlink" title="Understanding LSTM Networks"></a>Understanding LSTM Networks</h1><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Understanding-LSTM-Networks&quot;&gt;&lt;a href=&quot;#Understanding-LSTM-Networks&quot; class=&quot;headerlink&quot; title=&quot;Understanding LSTM Networks&quot;&gt;&lt;/a&gt;Under</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="RNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RNN/"/>
    
    <category term="LSTM" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RNN/LSTM/"/>
    
    
    <category term="LSTM" scheme="http://example.com/tags/LSTM/"/>
    
    <category term="RNN" scheme="http://example.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 感受野</title>
    <link href="http://example.com/2021/11/11/%E6%84%9F%E5%8F%97%E9%87%8E/"/>
    <id>http://example.com/2021/11/11/%E6%84%9F%E5%8F%97%E9%87%8E/</id>
    <published>2021-11-11T12:54:57.000Z</published>
    <updated>2021-11-13T04:11:57.640Z</updated>
    
    <content type="html"><![CDATA[<h1 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h1><p><a href="https://www.cnblogs.com/shine-lee/p/12069176.html">Click Here!</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;感受野&quot;&gt;&lt;a href=&quot;#感受野&quot; class=&quot;headerlink&quot; title=&quot;感受野&quot;&gt;&lt;/a&gt;感受野&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/shine-lee/p/12069176.html&quot;&gt;Click </summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    
    <category term="感受野" scheme="http://example.com/tags/%E6%84%9F%E5%8F%97%E9%87%8E/"/>
    
  </entry>
  
  <entry>
    <title>参考文献 | Remaining Useful Life Prediction of Machining Tools by 1D-CNN LSTM Network</title>
    <link href="http://example.com/2021/11/09/CnnLstmForRemainingUsefulLifePrediction/"/>
    <id>http://example.com/2021/11/09/CnnLstmForRemainingUsefulLifePrediction/</id>
    <published>2021-11-09T13:12:30.000Z</published>
    <updated>2021-11-09T13:42:27.512Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Remaining-Useful-Life-Prediction-of-Machining-Tools-by-1D-CNN-LSTM-Network"><a href="#Remaining-Useful-Life-Prediction-of-Machining-Tools-by-1D-CNN-LSTM-Network" class="headerlink" title="Remaining Useful Life Prediction of Machining Tools by 1D-CNN LSTM Network"></a>Remaining Useful Life Prediction of Machining Tools by 1D-CNN LSTM Network</h1><h2 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h2><p>use a 1D-CNN LSTM network architecture for machining tools RUL prediction</p><h2 id="Problem-Addressing"><a href="#Problem-Addressing" class="headerlink" title="Problem Addressing"></a>Problem Addressing</h2><p>Traditional machine learning algorithms are sometimes difficult to extract hidden information that characterizes the degradation process of the tool.<br>deep learning methods tend to have better effects, as it has powerful adaptive learning and anti-noise ability, and it can automatically extract deep<br> features, which is more versatile than traditional machine learning methods.</p><h2 id="Why-CNN-LSTM"><a href="#Why-CNN-LSTM" class="headerlink" title="Why CNN-LSTM?"></a>Why CNN-LSTM?</h2><p>CNN has a its capacity to automatically extract features and LSTM can effectively mine the hidden information in time series.</p><p>In fact, we can combine CNN’s high-dimensional feature extraction capacity and LSTM’s advantage on time series problems. After CNN extracts<br>features, we input them into the LSTM for training, then some improvements in accuracy and speed can be achieved.</p><p>For time-series problems, one dimensional convolutional neural network (1D-CNN) is more suitable than common convolution neural network. One of the<br>characteristics of the 1D-CNN is that for time-series data, the receptive field moves only in the direction of time, so the local inter-variable correlation can be extracted.</p><h2 id="Some-knowledge-points-learned"><a href="#Some-knowledge-points-learned" class="headerlink" title="Some knowledge points learned"></a>Some knowledge points learned</h2><ol><li>Each convolutional layer consists of several convolutional units whose parameters are optimized by backpropagation algorithms.</li><li>Pooling can effectively reduce the amount of data and increse the calculation speed.</li><li>Each unit of RNN is a simple chain structure, it processes the input sequence {x1,x2,…,xT} sequentially to construct a corresponding sequence of hidden states {h1,h2,…,hT}.</li><li>The main purpose of the dropout layer is to reduce over-fitting.<h2 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h2></li><li>compare the results of 1D-CNN,LSTM and 1D-CNN LSTM in own work.</li><li>write own paper according to this reference(part of introduction and network description)</li><li>Refer to the chart in the article</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Remaining-Useful-Life-Prediction-of-Machining-Tools-by-1D-CNN-LSTM-Network&quot;&gt;&lt;a href=&quot;#Remaining-Useful-Life-Prediction-of-Machining-</summary>
      
    
    
    
    <category term="Rsearch and Paper" scheme="http://example.com/categories/Rsearch-and-Paper/"/>
    
    <category term="EEG" scheme="http://example.com/categories/Rsearch-and-Paper/EEG/"/>
    
    <category term="脑电分类" scheme="http://example.com/categories/Rsearch-and-Paper/EEG/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/"/>
    
    <category term="参考文献" scheme="http://example.com/categories/Rsearch-and-Paper/EEG/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/"/>
    
    
    <category term="CNN+LSTM" scheme="http://example.com/tags/CNN-LSTM/"/>
    
    <category term="反向传播算法" scheme="http://example.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>参考文献 | A CNN-LSTM for Motor Imagery EEG Detection</title>
    <link href="http://example.com/2021/11/09/CNNLSTMMotorImageryEEGDetection/"/>
    <id>http://example.com/2021/11/09/CNNLSTMMotorImageryEEGDetection/</id>
    <published>2021-11-09T12:17:17.000Z</published>
    <updated>2021-11-09T12:40:46.476Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-CNN-LSTM-for-Motor-Imagery-EEG-Detection"><a href="#A-CNN-LSTM-for-Motor-Imagery-EEG-Detection" class="headerlink" title="A CNN-LSTM for Motor Imagery EEG Detection"></a>A CNN-LSTM for Motor Imagery EEG Detection</h1><h2 id="Why-CNN-LSTM"><a href="#Why-CNN-LSTM" class="headerlink" title="Why CNN-LSTM?"></a>Why CNN-LSTM?</h2><p>CNN layers detect better the spatial component of the data selecting the best features for us and RNN detect better the temporal component of the data.<br>(CNN layer is used to extract the most relevant features from the brain waves and LSTM is used to classify the time series.)</p><span id="more"></span><h2 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h2><p>1.proposed method of CNN-LSTM.<br>2.discussed the influence of using raw data over using the data split in frequency bands in the model proposed.<br>3.discuss the influence of certain frequency bands activity over other frequency bands.</p><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>the 5 types of waves (alpha, beta, theta, delta and gamma) are needed for an accurate classification and the raw data is not enough to ensure the accuracy of the results. </p><h2 id="Cite-This"><a href="#Cite-This" class="headerlink" title="Cite This"></a>Cite This</h2><p>F. M. Garcia-Moreno, M. Bermudez-Edo, M. J. Rodríguez-Fórtiz and J. L. Garrido, “A CNN-LSTM Deep Learning Classifier for Motor Imagery EEG Detection Using a Low-invasive and Low-Cost BCI Headband,” 2020 16th International Conference on Intelligent Environments (IE), 2020, pp. 84-91, doi: 10.1109/IE49459.2020.9155016.</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;A-CNN-LSTM-for-Motor-Imagery-EEG-Detection&quot;&gt;&lt;a href=&quot;#A-CNN-LSTM-for-Motor-Imagery-EEG-Detection&quot; class=&quot;headerlink&quot; title=&quot;A CNN-LSTM for Motor Imagery EEG Detection&quot;&gt;&lt;/a&gt;A CNN-LSTM for Motor Imagery EEG Detection&lt;/h1&gt;&lt;h2 id=&quot;Why-CNN-LSTM&quot;&gt;&lt;a href=&quot;#Why-CNN-LSTM&quot; class=&quot;headerlink&quot; title=&quot;Why CNN-LSTM?&quot;&gt;&lt;/a&gt;Why CNN-LSTM?&lt;/h2&gt;&lt;p&gt;CNN layers detect better the spatial component of the data selecting the best features for us and RNN detect better the temporal component of the data.&lt;br&gt;(CNN layer is used to extract the most relevant features from the brain waves and LSTM is used to classify the time series.)&lt;/p&gt;</summary>
    
    
    
    <category term="Research and Paper" scheme="http://example.com/categories/Research-and-Paper/"/>
    
    <category term="EEG" scheme="http://example.com/categories/Research-and-Paper/EEG/"/>
    
    <category term="脑电分类" scheme="http://example.com/categories/Research-and-Paper/EEG/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/"/>
    
    <category term="参考文献" scheme="http://example.com/categories/Research-and-Paper/EEG/%E8%84%91%E7%94%B5%E5%88%86%E7%B1%BB/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/"/>
    
    
    <category term="CNN+LSTM" scheme="http://example.com/tags/CNN-LSTM/"/>
    
    <category term="EEG Classification" scheme="http://example.com/tags/EEG-Classification/"/>
    
    <category term="EEG" scheme="http://example.com/tags/EEG/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 | 网络、模型、算法的区别</title>
    <link href="http://example.com/2021/11/09/%E7%BD%91%E7%BB%9Cand%E6%A8%A1%E5%9E%8Band%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://example.com/2021/11/09/%E7%BD%91%E7%BB%9Cand%E6%A8%A1%E5%9E%8Band%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2021-11-09T12:03:08.000Z</published>
    <updated>2021-11-09T12:06:05.043Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网络、模型、算法的区别"><a href="#网络、模型、算法的区别" class="headerlink" title="网络、模型、算法的区别"></a>网络、模型、算法的区别</h1><p>网络: 一种简单的网络结构，不包含任何权重参数。</p><p>模型： 设计一个网络后，在某些数据集上进行训练，得到一个包含权重参数的数据，称为模型。</p><p>算法： 在模型的基础上通过一些代码具体实现某些相关目的，这些代码以及模型文件等等资源被称为某算法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;网络、模型、算法的区别&quot;&gt;&lt;a href=&quot;#网络、模型、算法的区别&quot; class=&quot;headerlink&quot; title=&quot;网络、模型、算法的区别&quot;&gt;&lt;/a&gt;网络、模型、算法的区别&lt;/h1&gt;&lt;p&gt;网络: 一种简单的网络结构，不包含任何权重参数。&lt;/p&gt;
&lt;p&gt;模型</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>python | 对象转json</title>
    <link href="http://example.com/2021/11/08/python%E5%AF%B9%E8%B1%A1%E8%BD%ACjson/"/>
    <id>http://example.com/2021/11/08/python%E5%AF%B9%E8%B1%A1%E8%BD%ACjson/</id>
    <published>2021-11-08T12:22:28.000Z</published>
    <updated>2021-11-09T02:36:55.180Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python对象转json"><a href="#python对象转json" class="headerlink" title="python对象转json"></a>python对象转json</h1><p>程序将python的对象转为json格式。</p><span id="more"></span><p><strong>train_data_cor.txt文件包含以下内容：</strong><br>james.txt 2-34,3:21,2,34,2.45,3.01,2:01,2:01,3:10,2-22<br>sarah.txt 2:58,2.58,2:39,2-25,2:55,2:54,2.18,2:55,2:55<br>julie.txt 2.59,2.11,2:11,2:23,3-10,2-23,3:10,3.21,3-21<br>mikey.txt 2:22,3.01,3:01,3.02,3:02,3.02,3:22,2.49,2:38</p><p><strong>code:</strong></p><pre><code>import jsonclass Athlete(json.JSONEncoder):    def __init__(self,a_name,a_dob=None,a_times=[]):        self.name = a_name        self.dob = a_dob        self.times = a_times    def top3(self):        return sorted(set([self.sanitize(t) for t in self.times]))[0:3]    def sanitize(self,time_string):        if &#39;-&#39; in time_string:            splitter = &#39;-&#39;        elif &#39;:&#39; in time_string:            splitter = &#39;:&#39;        else:            return (time_string)        (mins,secs) = time_string.split(splitter)        return (mins+&#39;.&#39;+secs)with open(&#39;train_data_cor.txt&#39;) as f:    data = f.readline().strip().split(&#39;,&#39;)    ath = Athlete(data.pop(0),data.pop(0),data)    print(ath)ath_json = json.dumps(ath.__dict__)# 将json形式变量保存到文件中with open(&#39;json.txt&#39;,&#39;w&#39;) as f:    json.dump(ath_json,f)    # 读取json文件内容    with open(&#39;json.txt&#39;) as f:    ath = json.load(f)    print(ath)</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;python对象转json&quot;&gt;&lt;a href=&quot;#python对象转json&quot; class=&quot;headerlink&quot; title=&quot;python对象转json&quot;&gt;&lt;/a&gt;python对象转json&lt;/h1&gt;&lt;p&gt;程序将python的对象转为json格式。&lt;/p&gt;</summary>
    
    
    
    <category term="python" scheme="http://example.com/categories/python/"/>
    
    <category term="基础" scheme="http://example.com/categories/python/%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
  </entry>
  
</feed>
