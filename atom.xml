<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Victory&#39;s Blog</title>
  
  <subtitle>非淡泊无以明志，非宁静无以致远</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-01-05T03:21:52.030Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>victory-liao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>期刊 | 脑电期刊</title>
    <link href="http://example.com/2022/01/04/%E8%84%91%E7%94%B5%E6%9C%9F%E5%88%8A/"/>
    <id>http://example.com/2022/01/04/%E8%84%91%E7%94%B5%E6%9C%9F%E5%88%8A/</id>
    <published>2022-01-05T03:17:28.000Z</published>
    <updated>2022-01-05T03:21:52.030Z</updated>
    
    <content type="html"><![CDATA[<h1 id="脑电期刊"><a href="#脑电期刊" class="headerlink" title="脑电期刊"></a>脑电期刊</h1><p>名称：Biomedical Siganl Processing and Control<br>网址：<a href="https://www.sciencedirect.com/journal/biomedical-signal-processing-and-control">Biomedical Signal Processing and Control</a><br>SCI分区：2</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;脑电期刊&quot;&gt;&lt;a href=&quot;#脑电期刊&quot; class=&quot;headerlink&quot; title=&quot;脑电期刊&quot;&gt;&lt;/a&gt;脑电期刊&lt;/h1&gt;&lt;p&gt;名称：Biomedical Siganl Processing and Control&lt;br&gt;网址：&lt;a href=&quot;htt</summary>
      
    
    
    
    <category term="Research and Paper" scheme="http://example.com/categories/Research-and-Paper/"/>
    
    <category term="脑电期刊" scheme="http://example.com/categories/Research-and-Paper/%E8%84%91%E7%94%B5%E6%9C%9F%E5%88%8A/"/>
    
    <category term="Biomedical Signal Processing and Control" scheme="http://example.com/categories/Research-and-Paper/%E8%84%91%E7%94%B5%E6%9C%9F%E5%88%8A/Biomedical-Signal-Processing-and-Control/"/>
    
    
  </entry>
  
  <entry>
    <title>最新SCI期刊查询及投稿分析系统</title>
    <link href="http://example.com/2021/12/16/%E6%9C%80%E6%96%B0SCI%E6%9C%9F%E5%88%8A%E6%9F%A5%E8%AF%A2%E5%8F%8A%E6%8A%95%E7%A8%BF%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/12/16/%E6%9C%80%E6%96%B0SCI%E6%9C%9F%E5%88%8A%E6%9F%A5%E8%AF%A2%E5%8F%8A%E6%8A%95%E7%A8%BF%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-12-17T06:44:04.000Z</published>
    <updated>2021-12-17T06:53:02.686Z</updated>
    
    <content type="html"><![CDATA[<h1 id="最新SCI期刊查询及投稿分析系统"><a href="#最新SCI期刊查询及投稿分析系统" class="headerlink" title="最新SCI期刊查询及投稿分析系统"></a>最新SCI期刊查询及投稿分析系统</h1><p><a href="https://www.letpub.com.cn/">最新SCI期刊查询及投稿分析系统</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;最新SCI期刊查询及投稿分析系统&quot;&gt;&lt;a href=&quot;#最新SCI期刊查询及投稿分析系统&quot; class=&quot;headerlink&quot; title=&quot;最新SCI期刊查询及投稿分析系统&quot;&gt;&lt;/a&gt;最新SCI期刊查询及投稿分析系统&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https</summary>
      
    
    
    
    <category term="Research and Paper" scheme="http://example.com/categories/Research-and-Paper/"/>
    
    <category term="最新SCI期刊查询及投稿分析系统" scheme="http://example.com/categories/Research-and-Paper/%E6%9C%80%E6%96%B0SCI%E6%9C%9F%E5%88%8A%E6%9F%A5%E8%AF%A2%E5%8F%8A%E6%8A%95%E7%A8%BF%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="SCI期刊查询" scheme="http://example.com/tags/SCI%E6%9C%9F%E5%88%8A%E6%9F%A5%E8%AF%A2/"/>
    
  </entry>
  
  <entry>
    <title>写论文神器</title>
    <link href="http://example.com/2021/12/16/%E5%86%99%E8%AE%BA%E6%96%87%E7%A5%9E%E5%99%A8/"/>
    <id>http://example.com/2021/12/16/%E5%86%99%E8%AE%BA%E6%96%87%E7%A5%9E%E5%99%A8/</id>
    <published>2021-12-17T06:35:39.000Z</published>
    <updated>2021-12-17T06:42:50.923Z</updated>
    
    <content type="html"><![CDATA[<h1 id="写论文神器-CTeX"><a href="#写论文神器-CTeX" class="headerlink" title="写论文神器-CTeX"></a>写论文神器-CTeX</h1><p><a href="http://www.ctex.org/CTeX">CTeX下载地址</a></p><p><a href="https://zhiqianghe.blog.csdn.net/article/details/102978653?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link">CTeX安装教程</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;写论文神器-CTeX&quot;&gt;&lt;a href=&quot;#写论文神器-CTeX&quot; class=&quot;headerlink&quot; title=&quot;写论文神器-CTeX&quot;&gt;&lt;/a&gt;写论文神器-CTeX&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://www.ctex.org/CTeX&quot;&gt;CTe</summary>
      
    
    
    
    <category term="Research and Paper" scheme="http://example.com/categories/Research-and-Paper/"/>
    
    <category term="CTeX写论文神器" scheme="http://example.com/categories/Research-and-Paper/CTeX%E5%86%99%E8%AE%BA%E6%96%87%E7%A5%9E%E5%99%A8/"/>
    
    
    <category term="CTeX" scheme="http://example.com/tags/CTeX/"/>
    
  </entry>
  
  <entry>
    <title>EmotionalTendencyPredictionUsingLSTM</title>
    <link href="http://example.com/2021/11/29/EmotionalTendencyPredictionUsingLSTM/"/>
    <id>http://example.com/2021/11/29/EmotionalTendencyPredictionUsingLSTM/</id>
    <published>2021-11-29T12:48:49.000Z</published>
    <updated>2021-11-29T12:48:49.761Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>paddle | 多层感知机</title>
    <link href="http://example.com/2021/11/29/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    <id>http://example.com/2021/11/29/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</id>
    <published>2021-11-29T12:36:00.000Z</published>
    <updated>2021-11-29T12:40:28.761Z</updated>
    
    
    
    
    <category term="项目经历" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/"/>
    
    <category term="Deep Learning" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/"/>
    
    <category term="PaddlePaddle" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/PaddlePaddle/"/>
    
    <category term="Multilayer Perceptron" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/PaddlePaddle/Multilayer-Perceptron/"/>
    
    
    <category term="paddle" scheme="http://example.com/tags/paddle/"/>
    
    <category term="多层感知机" scheme="http://example.com/tags/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>PIL | PIL.Image.crop()</title>
    <link href="http://example.com/2021/11/22/PILImageCrop/"/>
    <id>http://example.com/2021/11/22/PILImageCrop/</id>
    <published>2021-11-22T09:27:54.000Z</published>
    <updated>2021-11-22T09:31:23.453Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PIL-Image-crop"><a href="#PIL-Image-crop" class="headerlink" title="PIL.Image.crop()"></a>PIL.Image.crop()</h1><p>程序使用PIL.Image.crop()将一张图片切割成9张小图片。</p><span id="more"></span><p><strong>show you the code:</strong></p><pre><code># -*- coding: utf-8 -*-from PIL import Imagefilename = r&#39;path of picture you want to crop&#39;img = Image.open(filename)size = img.sizeprint(size)# 准备将图片切割成9张小图片weight = int(size[0] // 3)height = int(size[1] // 3)# 切割后的小图的宽度和高度print(weight, height)for j in range(3):    for i in range(3):        box = (weight * i, height * j, weight * (i + 1), height * (j + 1))        region = img.crop(box)        region.save(&#39;&#123;&#125;&#123;&#125;.png&#39;.format(j, i))</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;PIL-Image-crop&quot;&gt;&lt;a href=&quot;#PIL-Image-crop&quot; class=&quot;headerlink&quot; title=&quot;PIL.Image.crop()&quot;&gt;&lt;/a&gt;PIL.Image.crop()&lt;/h1&gt;&lt;p&gt;程序使用PIL.Image.crop()将一张图片切割成9张小图片。&lt;/p&gt;</summary>
    
    
    
    <category term="python" scheme="http://example.com/categories/python/"/>
    
    <category term="第三方库" scheme="http://example.com/categories/python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"/>
    
    <category term="PIL" scheme="http://example.com/categories/python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/PIL/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
    <category term="PIL" scheme="http://example.com/tags/PIL/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 | 深度学习pytorch训练代码模板</title>
    <link href="http://example.com/2021/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0pytorch%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF/"/>
    <id>http://example.com/2021/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0pytorch%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%E6%A8%A1%E6%9D%BF/</id>
    <published>2021-11-21T12:13:30.000Z</published>
    <updated>2021-11-21T12:15:17.983Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习pytorch训练代码模板"><a href="#深度学习pytorch训练代码模板" class="headerlink" title="深度学习pytorch训练代码模板"></a>深度学习pytorch训练代码模板</h1><p><a href="https://zhuanlan.zhihu.com/p/396666255?utm_source=wechat_session&utm_medium=social&utm_oi=1006101315038175232&utm_campaign=shareopn">查看模板！</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;深度学习pytorch训练代码模板&quot;&gt;&lt;a href=&quot;#深度学习pytorch训练代码模板&quot; class=&quot;headerlink&quot; title=&quot;深度学习pytorch训练代码模板&quot;&gt;&lt;/a&gt;深度学习pytorch训练代码模板&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;h</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>RNN | LSTM输入输出格式</title>
    <link href="http://example.com/2021/11/21/LSTM%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F/"/>
    <id>http://example.com/2021/11/21/LSTM%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F/</id>
    <published>2021-11-21T12:07:15.000Z</published>
    <updated>2021-11-21T12:10:08.192Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LSTM模型结构的可视化"><a href="#LSTM模型结构的可视化" class="headerlink" title="LSTM模型结构的可视化"></a>LSTM模型结构的可视化</h1><p><a href="https://zhuanlan.zhihu.com/p/139617364?utm_source=wechat_session&utm_medium=social&utm_oi=1006101315038175232&utm_campaign=shareopn">非常到位的LSTM解读！</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;LSTM模型结构的可视化&quot;&gt;&lt;a href=&quot;#LSTM模型结构的可视化&quot; class=&quot;headerlink&quot; title=&quot;LSTM模型结构的可视化&quot;&gt;&lt;/a&gt;LSTM模型结构的可视化&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhih</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="RNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RNN/"/>
    
    <category term="LSTM" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/RNN/LSTM/"/>
    
    
    <category term="LSTM" scheme="http://example.com/tags/LSTM/"/>
    
    <category term="RNN" scheme="http://example.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>Computer Vision | 虚假名人照片生成</title>
    <link href="http://example.com/2021/11/20/%E8%99%9A%E5%81%87%E5%90%8D%E4%BA%BA%E7%85%A7%E7%89%87%E7%94%9F%E6%88%90/"/>
    <id>http://example.com/2021/11/20/%E8%99%9A%E5%81%87%E5%90%8D%E4%BA%BA%E7%85%A7%E7%89%87%E7%94%9F%E6%88%90/</id>
    <published>2021-11-20T10:02:52.000Z</published>
    <updated>2021-11-20T12:14:26.127Z</updated>
    
    <content type="html"><![CDATA[<h1 id="虚假名人照片生成"><a href="#虚假名人照片生成" class="headerlink" title="虚假名人照片生成"></a>虚假名人照片生成</h1><h2 id="1-虚假照片生成有什么用？"><a href="#1-虚假照片生成有什么用？" class="headerlink" title="1. 虚假照片生成有什么用？"></a>1. 虚假照片生成有什么用？</h2><p>生成一些“并不存在的人”的照片<br>给定一系列真人照片，通过GAN技术生成一些类似的照片。但这些照片上的人并不真实存在。<br>这些照片可以用作一些影视作品中的“遗像”，这样，既保证了影视作品的真实性，又不需要使用真人照片。</p><h2 id="2-数据集情况"><a href="#2-数据集情况" class="headerlink" title="2.数据集情况"></a>2.数据集情况</h2><p>CelebA（名人照片数据集）<br>网址：<a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</a><br><strong>·</strong> 人脸照片，拥有超过200K张名人照片<br><strong>·</strong> 照片中人的姿态不一，背景杂乱</p><h2 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h2><p>DCGAN generator</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;虚假名人照片生成&quot;&gt;&lt;a href=&quot;#虚假名人照片生成&quot; class=&quot;headerlink&quot; title=&quot;虚假名人照片生成&quot;&gt;&lt;/a&gt;虚假名人照片生成&lt;/h1&gt;&lt;h2 id=&quot;1-虚假照片生成有什么用？&quot;&gt;&lt;a href=&quot;#1-虚假照片生成有什么用？&quot; c</summary>
      
    
    
    
    <category term="项目经历" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/"/>
    
    <category term="Deep Learning" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/"/>
    
    <category term="Computer Vision" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/"/>
    
    <category term="虚假名人照片生成" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/%E8%99%9A%E5%81%87%E5%90%8D%E4%BA%BA%E7%85%A7%E7%89%87%E7%94%9F%E6%88%90/"/>
    
    
    <category term="虚假名人照片生成" scheme="http://example.com/tags/%E8%99%9A%E5%81%87%E5%90%8D%E4%BA%BA%E7%85%A7%E7%89%87%E7%94%9F%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>Computer Vision | 基于ResNet的CIFAER10图像分类</title>
    <link href="http://example.com/2021/11/16/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    <id>http://example.com/2021/11/16/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</id>
    <published>2021-11-17T03:26:33.000Z</published>
    <updated>2021-11-20T09:51:10.207Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于ResNet的CIFAER-10图像分类"><a href="#基于ResNet的CIFAER-10图像分类" class="headerlink" title="基于ResNet的CIFAER-10图像分类"></a>基于ResNet的CIFAER-10图像分类</h1><h2 id="CIFAR-10数据集"><a href="#CIFAR-10数据集" class="headerlink" title="CIFAR-10数据集"></a>CIFAR-10数据集</h2><p><strong>数据集规模</strong><br>60000张32×32的彩色图片，共有十个类别，每个类别6000张图片。共50000张训练集图片和10000测试集图片。<br><strong>数据集样本类别</strong><br>飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车（汽车和卡车无重叠）—&gt; 10分类任务<br><strong>数据集网址</strong><br><a href="http://www.cs.toronto.edu/~kriz/cifar.html">http://www.cs.toronto.edu/~kriz/cifar.html</a><br><strong>网络</strong><br>ResNet18</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于ResNet的CIFAER-10图像分类&quot;&gt;&lt;a href=&quot;#基于ResNet的CIFAER-10图像分类&quot; class=&quot;headerlink&quot; title=&quot;基于ResNet的CIFAER-10图像分类&quot;&gt;&lt;/a&gt;基于ResNet的CIFAER-10图像</summary>
      
    
    
    
    <category term="项目经历" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/"/>
    
    <category term="Deep Learning" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/"/>
    
    <category term="Computer Vision" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/"/>
    
    <category term="基于ResNet的CIFAER-10图像分类" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER-10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
    
    <category term="基于ResNet的CIFAER-10图像分类" scheme="http://example.com/tags/%E5%9F%BA%E4%BA%8EResNet%E7%9A%84CIFAER-10%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>Computer Vision | DogsVSCats</title>
    <link href="http://example.com/2021/11/16/DogsVSCats/"/>
    <id>http://example.com/2021/11/16/DogsVSCats/</id>
    <published>2021-11-17T02:34:35.000Z</published>
    <updated>2021-11-20T09:57:33.144Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dogs-VS-Cats"><a href="#Dogs-VS-Cats" class="headerlink" title="Dogs VS Cats"></a>Dogs VS Cats</h1><h2 id="猫狗大战任务"><a href="#猫狗大战任务" class="headerlink" title="猫狗大战任务"></a>猫狗大战任务</h2><p>猫狗大战是来源于Kaggle的一个比赛项目，任务为给定一个有猫狗照片数据集，设计一种算法对测试集中的猫狗图片进行分类。<br><strong>比赛项目网址：</strong><br><a href="https://www.kaggle.com/">https://www.kaggle.com/</a><br><strong>网络</strong></p><pre><code>layer1: Conv2d(3, 16, 3, padding=1)layer2: relu():layer3: max_pool2d(2)layer4: Conv2d(16, 16, 3, padding=1)layer5: relu()layer6: max_pool2d(2)layer7: Linear(50*50*16, 128)layer8: relu()layer9: Linear(128, 64)layer10: relu()layer11: Linear(64, 2)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Dogs-VS-Cats&quot;&gt;&lt;a href=&quot;#Dogs-VS-Cats&quot; class=&quot;headerlink&quot; title=&quot;Dogs VS Cats&quot;&gt;&lt;/a&gt;Dogs VS Cats&lt;/h1&gt;&lt;h2 id=&quot;猫狗大战任务&quot;&gt;&lt;a href=&quot;#猫狗大战任务&quot;</summary>
      
    
    
    
    <category term="项目经历" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/"/>
    
    <category term="Deep Learning" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/"/>
    
    <category term="Computer Vision" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/"/>
    
    <category term="Dogs VS Cats" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86/Deep-Learning/Computer-Vision/Dogs-VS-Cats/"/>
    
    
    <category term="Dogs VS Cats" scheme="http://example.com/tags/Dogs-VS-Cats/"/>
    
  </entry>
  
  <entry>
    <title>脑电伪迹降噪方法整理</title>
    <link href="http://example.com/2021/11/15/%E8%84%91%E7%94%B5%E4%BC%AA%E8%BF%B9%E9%99%8D%E5%99%AA%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
    <id>http://example.com/2021/11/15/%E8%84%91%E7%94%B5%E4%BC%AA%E8%BF%B9%E9%99%8D%E5%99%AA%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/</id>
    <published>2021-11-15T13:31:27.000Z</published>
    <updated>2021-11-15T13:33:18.619Z</updated>
    
    <content type="html"><![CDATA[<h1 id="脑电伪迹降噪方法整理"><a href="#脑电伪迹降噪方法整理" class="headerlink" title="脑电伪迹降噪方法整理"></a>脑电伪迹降噪方法整理</h1><p><a href="https://mp.weixin.qq.com/s/gRIP-fuYsZv2p92qptOmew">脑电伪迹降噪方法整理</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;脑电伪迹降噪方法整理&quot;&gt;&lt;a href=&quot;#脑电伪迹降噪方法整理&quot; class=&quot;headerlink&quot; title=&quot;脑电伪迹降噪方法整理&quot;&gt;&lt;/a&gt;脑电伪迹降噪方法整理&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/gR</summary>
      
    
    
    
    <category term="Research and Paper" scheme="http://example.com/categories/Research-and-Paper/"/>
    
    <category term="EEG" scheme="http://example.com/categories/Research-and-Paper/EEG/"/>
    
    <category term="伪迹移除" scheme="http://example.com/categories/Research-and-Paper/EEG/%E4%BC%AA%E8%BF%B9%E7%A7%BB%E9%99%A4/"/>
    
    <category term="脑电伪迹降噪方法整理" scheme="http://example.com/categories/Research-and-Paper/EEG/%E4%BC%AA%E8%BF%B9%E7%A7%BB%E9%99%A4/%E8%84%91%E7%94%B5%E4%BC%AA%E8%BF%B9%E9%99%8D%E5%99%AA%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
    
    
    <category term="伪迹移除" scheme="http://example.com/tags/%E4%BC%AA%E8%BF%B9%E7%A7%BB%E9%99%A4/"/>
    
    <category term="EEG" scheme="http://example.com/tags/EEG/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 | 模型存储的5种方法</title>
    <link href="http://example.com/2021/11/15/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8%E7%9A%845%E4%B8%AD%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2021/11/15/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8%E7%9A%845%E4%B8%AD%E6%96%B9%E6%B3%95/</id>
    <published>2021-11-15T13:01:09.000Z</published>
    <updated>2021-11-15T13:06:48.166Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型存储的5种方法"><a href="#模型存储的5种方法" class="headerlink" title="模型存储的5种方法"></a>模型存储的5种方法</h1><p><strong>方法1：csv/txt</strong><br>存储为csv、text或者json是最为简单的存储格式，阅读和解析起来非常方便。<br>如果使用Pandas则可以在存储的过程中设置压缩方法，对磁盘比较友好。</p><p><strong>·</strong> 场景：通用<br><strong>·</strong> 数据：表格、文本<br><strong>·</strong> 文件大小：压缩后较少<br><strong>·</strong> 读取速度：较慢</p><pre><code>compression_opts = dict(method=&#39;zip&#39;,                        archive_name=&#39;out.csv&#39;)  df.to_csv(&#39;out.zip&#39;, index=False,          compression=compression_opts) </code></pre><p><strong>方法2：hdf</strong><br>HDF(Hierarchical Data File)是能满足各种领域研究需求而研制的一种能高效存储和分发科学数据的新型数据格式。<br>HDF格式支持分层存储，可以将多个变量同时存在一个HDF文件中，同时在读取速度上也比较快。</p><p><strong>·</strong> 场景：通用<br><strong>·</strong> 数据：表格、文本<br><strong>·</strong> 文件大小：较大<br><strong>·</strong> 读取速度：较快</p><pre><code>df = pd.DataFrame(&#123;&#39;A&#39;: [1, 2, 3], &#39;B&#39;: [4, 5, 6]&#125;,                  index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])df.to_hdf(&#39;data.h5&#39;, key=&#39;df&#39;, mode=&#39;w&#39;)</code></pre><p><strong>方法3：npy</strong><br>如果将特征和数据处理为Numpy格式，则可以考虑存储为Numpy中的npy或npz格式。</p><p><strong>·</strong> 场景：文件存储<br><strong>·</strong> 数据：矩阵<br><strong>·</strong> 文件大小：适中<br><strong>·</strong> 读取速度：较快</p><ol><li>npy文件：二进制格式<br>np.load()和np.save()是读写磁盘数组数据的两个重要函数。使用时数组会以未压缩的原始二进制格式保存在扩展名为.npy的文件中。</li></ol><pre><code>import numpy as nparr=np.arange(5)np.save(&#39;test&#39;,arr)print(np.load(&#39;test.npy&#39;))</code></pre><p>2.npz文件：压缩文件<br>使用np.savez()函数可以将多个数组保存到同一个文件中。读取.npz文件时使用np.load()函数，返回的是一个类似于字典的对象，因此可以通过数组名作为关键字对多个数组进行访问。</p><pre><code>import numpy as npa = np.arange(5)b = np.arange(6)c = np.arange(7)np.savez(&#39;test&#39;, a, b, c_array=c)  # c_array是数组c的命名data = np.load(&#39;test.npz&#39;)print(&#39;arr_0 : &#39;, data[&#39;arr_0&#39;])print(&#39;arr_1 : &#39;, data[&#39;arr_1&#39;])print(&#39;c_array : &#39;, data[&#39;c_array&#39;])</code></pre><p><strong>方法4：memmap</strong><br>NumPy实现了一个类似于ndarray的memmap对象，它允许将大文件分成小段进行读写，而不是一次性将整个数组读入内存。</p><p>如果需要存储的对象大于内存，则可以选择memmap进行存储。</p><p><strong>·</strong> 场景：大文件存储<br><strong>·</strong> 数据：矩阵<br><strong>·</strong> 文件大小：较大、特别大<br><strong>·</strong> 读取速度：适中</p><pre><code>newfp = np.memmap(filename, dtype=&#39;float32&#39;, mode=&#39;r&#39;, shape=(3,4))fpc[0,:] = 0</code></pre><p><strong>方法5：joblib</strong><br>类似于pkl存储，joblib.dump可以将任意的Python对象持久化到一个文件中，并使用joblib.load进行读取。</p><p><strong>·</strong> 场景：任意<br><strong>·</strong> 数据：任意<br><strong>·</strong> 文件大小：适中<br><strong>·</strong> 读取速度：适中</p><pre><code>from joblib import load, dumpX = [[0, 0], [1, 1]]Y = [1, 0]dump((X, Y), &quot;data.pkl&quot;)X, Y = load(&quot;data.pkl&quot;)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;模型存储的5种方法&quot;&gt;&lt;a href=&quot;#模型存储的5种方法&quot; class=&quot;headerlink&quot; title=&quot;模型存储的5种方法&quot;&gt;&lt;/a&gt;模型存储的5种方法&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;方法1：csv/txt&lt;/strong&gt;&lt;br&gt;存储为csv、tex</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="模型存储" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="模型存储" scheme="http://example.com/tags/%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 卷积神经网络之卷积计算作用与思想</title>
    <link href="http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E4%BD%9C%E7%94%A8%E4%B8%8E%E6%80%9D%E6%83%B3/"/>
    <id>http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%8D%B7%E7%A7%AF%E8%AE%A1%E7%AE%97%E4%BD%9C%E7%94%A8%E4%B8%8E%E6%80%9D%E6%83%B3/</id>
    <published>2021-11-15T12:57:16.000Z</published>
    <updated>2021-11-15T12:58:41.489Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络之卷积计算作用与思想"><a href="#卷积神经网络之卷积计算作用与思想" class="headerlink" title="卷积神经网络之卷积计算作用与思想"></a>卷积神经网络之卷积计算作用与思想</h1><p><a href="https://www.cnblogs.com/shine-lee/p/9932226.html">卷积神经网络之卷积计算、作用与思想</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;卷积神经网络之卷积计算作用与思想&quot;&gt;&lt;a href=&quot;#卷积神经网络之卷积计算作用与思想&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络之卷积计算作用与思想&quot;&gt;&lt;/a&gt;卷积神经网络之卷积计算作用与思想&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="卷积" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/%E5%8D%B7%E7%A7%AF/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="卷积" scheme="http://example.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 卷积和卷积核</title>
    <link href="http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8/"/>
    <id>http://example.com/2021/11/15/%E5%8D%B7%E7%A7%AF%E5%92%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8/</id>
    <published>2021-11-15T12:29:06.000Z</published>
    <updated>2021-11-15T12:31:58.186Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积和卷积核"><a href="#卷积和卷积核" class="headerlink" title="卷积和卷积核"></a>卷积和卷积核</h1><p>1.卷积<br>原理:卷积过程就是卷积核行列对称翻转后,在图像上滑动,并且依次相乘求和.(与滤波器不同的一点就是多了一个卷积核翻转的过程).然后经过池化,激活后输入下一层.<br>单个卷积层可以提取特征,当多个卷积叠加后即可逐步学习出更高语义的抽象特征.<br>2.卷积核<br>卷积核:其中卷积核主要有两类,普通卷积核和1<em>1的卷积核.普通卷积核同时改变图像的空间域和通道域,如下图所示,每个卷积核的通道数与输入相同,<br>卷积后会得到一个通道为一的特征图,我们希望卷积后的通道数有几个,卷积核就有几个.<br>1</em>1卷积核,视野大小为单个特征位点,能够实现在空间域不改变的情况下实现通道域信息的交流,<br>并且获得我们想要的通道数量(一般是降维).</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;卷积和卷积核&quot;&gt;&lt;a href=&quot;#卷积和卷积核&quot; class=&quot;headerlink&quot; title=&quot;卷积和卷积核&quot;&gt;&lt;/a&gt;卷积和卷积核&lt;/h1&gt;&lt;p&gt;1.卷积&lt;br&gt;原理:卷积过程就是卷积核行列对称翻转后,在图像上滑动,并且依次相乘求和.(与滤波器不同的一点</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="卷积" scheme="http://example.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
    <category term="卷积核" scheme="http://example.com/tags/%E5%8D%B7%E7%A7%AF%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>VGG | 使用3x3卷积核的优点</title>
    <link href="http://example.com/2021/11/15/VGG3x3%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%BC%98%E7%82%B9/"/>
    <id>http://example.com/2021/11/15/VGG3x3%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%BC%98%E7%82%B9/</id>
    <published>2021-11-15T12:24:44.000Z</published>
    <updated>2021-11-15T12:26:22.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="VGG使用3x3卷积核的优点"><a href="#VGG使用3x3卷积核的优点" class="headerlink" title="VGG使用3x3卷积核的优点"></a>VGG使用3x3卷积核的优点</h1><p>2个3x3的卷积核串联和一个5x5的卷积核拥有相同的感受野，但是，2个3x3的卷积核拥有更少的参数，<br>对于通道为1的5x5特征图得到通道为1的输出特征图，前者有3x3x2=18个参数，后者5x5=25个参数，<br>其次，多个3x3的卷积核比一个较大的尺寸的卷积核加入了更多的非线性函数，增强了模型的非线性表达能力。<br><strong>1x1卷积核的作用：</strong> 改变通道数目，保持尺度不变情况下增强非线性表达能力，可以实现跨通道的信息交互。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;VGG使用3x3卷积核的优点&quot;&gt;&lt;a href=&quot;#VGG使用3x3卷积核的优点&quot; class=&quot;headerlink&quot; title=&quot;VGG使用3x3卷积核的优点&quot;&gt;&lt;/a&gt;VGG使用3x3卷积核的优点&lt;/h1&gt;&lt;p&gt;2个3x3的卷积核串联和一个5x5的卷积核拥</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="VGG" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/VGG/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="VGG" scheme="http://example.com/tags/VGG/"/>
    
  </entry>
  
  <entry>
    <title>CNN | BatchNormalization</title>
    <link href="http://example.com/2021/11/15/BatchNormalization/"/>
    <id>http://example.com/2021/11/15/BatchNormalization/</id>
    <published>2021-11-15T12:22:11.000Z</published>
    <updated>2021-11-15T12:23:39.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="BatchNormalization"><a href="#BatchNormalization" class="headerlink" title="BatchNormalization"></a>BatchNormalization</h1><p>由于深度神经网络涉及到很多层的叠加，而每一层的参数更新会导致上层的输入数据分布发生变化，<br>通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。<br>为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。<br>也就是随是着网络加深，参数分布不断往激活函数两端移动(梯度变小)，导致反向传播出现梯度消失，收敛困难。<br>原理：可在每层的激活函数前，加入BN，将参数重新拉回0-1正态分布，加速收敛。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;BatchNormalization&quot;&gt;&lt;a href=&quot;#BatchNormalization&quot; class=&quot;headerlink&quot; title=&quot;BatchNormalization&quot;&gt;&lt;/a&gt;BatchNormalization&lt;/h1&gt;&lt;p&gt;由于深度神经</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="Batch Normalization" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/Batch-Normalization/"/>
    
    
    <category term="Batch Normalization" scheme="http://example.com/tags/Batch-Normalization/"/>
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>numpy | shuffle数据</title>
    <link href="http://example.com/2021/11/15/shuffle%E6%95%B0%E6%8D%AE/"/>
    <id>http://example.com/2021/11/15/shuffle%E6%95%B0%E6%8D%AE/</id>
    <published>2021-11-15T12:14:50.000Z</published>
    <updated>2021-11-15T12:17:53.666Z</updated>
    
    <content type="html"><![CDATA[<h1 id="shuffle数据"><a href="#shuffle数据" class="headerlink" title="shuffle数据"></a>shuffle数据</h1><p>在使用大量的数据来训练深度学习模型时，我们有可能需要对训练数据和数据标签进行shuffle(打乱)操作。</p><span id="more"></span><p><strong>show you the example code:</strong></p><pre><code>data = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])y = np.array([1, 2, 3, 4, 5])print(&#39;-------原数据：----------&#39;)print(&#39;数据：&#39;, data)print(&#39;标签：&#39;, y)print(&#39;-------打乱数据：----------&#39;)np.random.seed(116)np.random.shuffle(data)np.random.seed(116)np.random.shuffle(y)print(&#39;数据：&#39;, data)print(&#39;标签：&#39;, y )</code></pre>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;shuffle数据&quot;&gt;&lt;a href=&quot;#shuffle数据&quot; class=&quot;headerlink&quot; title=&quot;shuffle数据&quot;&gt;&lt;/a&gt;shuffle数据&lt;/h1&gt;&lt;p&gt;在使用大量的数据来训练深度学习模型时，我们有可能需要对训练数据和数据标签进行shuffle(打乱)操作。&lt;/p&gt;</summary>
    
    
    
    <category term="python" scheme="http://example.com/categories/python/"/>
    
    <category term="第三方库" scheme="http://example.com/categories/python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"/>
    
    <category term="numpy" scheme="http://example.com/categories/python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/numpy/"/>
    
    
    <category term="numpy" scheme="http://example.com/tags/numpy/"/>
    
    <category term="shuffle" scheme="http://example.com/tags/shuffle/"/>
    
  </entry>
  
  <entry>
    <title>深度学习 | 深度学习基础问题</title>
    <link href="http://example.com/2021/11/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2021/11/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E9%97%AE%E9%A2%98/</id>
    <published>2021-11-15T04:31:53.000Z</published>
    <updated>2021-11-21T12:15:31.267Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习基础问题"><a href="#深度学习基础问题" class="headerlink" title="深度学习基础问题"></a>深度学习基础问题</h1><p><a href="https://mp.weixin.qq.com/s/KcIlkLyNROxC_TUbCDhEmg">深度学习基础问题</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;深度学习基础问题&quot;&gt;&lt;a href=&quot;#深度学习基础问题&quot; class=&quot;headerlink&quot; title=&quot;深度学习基础问题&quot;&gt;&lt;/a&gt;深度学习基础问题&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/KcIlkLyNRO</summary>
      
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>CNN | 卷积的三种模式</title>
    <link href="http://example.com/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"/>
    <id>http://example.com/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/</id>
    <published>2021-11-15T04:21:19.000Z</published>
    <updated>2021-11-15T04:27:26.593Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积的三种模式"><a href="#卷积的三种模式" class="headerlink" title="卷积的三种模式"></a>卷积的三种模式</h1><p>通常用外部api进行卷积的时候，会面临mode选择<br>其实这三种不同模式是对卷积核移动范围的不同限制<br>设 image的大小是7x7，filter的大小是3x3</p><span id="more"></span><p><strong>full mode:</strong><br>橙色部分为image, 蓝色部分为filter。full模式的意思是，从filter和image刚相交开始做卷积，白色部分为填0。filter的运动范围如图所示。<br><img src="/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/1.jpg"><br><strong>same mode:</strong><br>当filter的中心(K)与image的边角重合时，开始做卷积运算，可见filter的运动范围比full模式小了一圈。注意：这里的same还有一个意思，卷积之后输出的feature map尺寸保持不变(相对于输入图片)。当然，same模式不代表完全输入输出尺寸一样，也跟卷积核的步长有关系。same模式也是最常见的模式，因为这种模式可以在前向传播的过程中让特征图的大小保持不变，调参师不需要精准计算其尺寸变化(因为尺寸根本就没变化)。<br><img src="/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/2.jpg"><br><strong>valid mode:</strong><br>当filter全部在image里面的时候，进行卷积运算，可见filter的移动范围较same更小了。<br><img src="/2021/11/14/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/3.jpg"></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;卷积的三种模式&quot;&gt;&lt;a href=&quot;#卷积的三种模式&quot; class=&quot;headerlink&quot; title=&quot;卷积的三种模式&quot;&gt;&lt;/a&gt;卷积的三种模式&lt;/h1&gt;&lt;p&gt;通常用外部api进行卷积的时候，会面临mode选择&lt;br&gt;其实这三种不同模式是对卷积核移动范围的不同限制&lt;br&gt;设 image的大小是7x7，filter的大小是3x3&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习基础" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
    <category term="CNN" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/"/>
    
    <category term="卷积的三种模式" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/CNN/%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="http://example.com/tags/CNN/"/>
    
    <category term="valid" scheme="http://example.com/tags/valid/"/>
    
    <category term="same" scheme="http://example.com/tags/same/"/>
    
    <category term="full" scheme="http://example.com/tags/full/"/>
    
  </entry>
  
</feed>
