<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>victory的博客</title>
  
  <subtitle>长安一片月，万户捣衣声</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-08-29T13:10:33.646Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>victory-liao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>AI | AI服务器高速互联技术</title>
    <link href="http://example.com/2024/08/29/AI%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF/"/>
    <id>http://example.com/2024/08/29/AI%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF/</id>
    <published>2024-08-29T12:41:23.000Z</published>
    <updated>2024-08-29T13:10:33.646Z</updated>
    
    <content type="html"><![CDATA[<p>三种 RDMA技术RoCE、iWARP，后两者是基于以太网的技术，IB的链路层进行了重新设计。</p><p>随着大模型以及AIGC的快速发展，AI对于算力有了更高的要求。从最开始使用单机单卡（CPU+GPU）进行DL模型训练推理，到使用单机多卡（CPU+GPUs），再到多机多卡的AI集群。</p><span id="more"></span><p>集中更多的算力可以加速AI模型的训练，但只有强大的AI算力是不够的，AI模型的训练是从大量数据中学习规律、学习知识，AI的训练过程设计大量的数据搬运，需要高带宽、低延时的数据传输。高速互联技术能够将不同的算力芯片或服务器连接在一起组成一个算力网络，并提供高速的数据传输能力。</p><p>高速互联分为结点内部计算设备的互联与结点间的互联。结点内互联又分为单节点互联与超级结点互联。单节点互联能够实现两个计算设备的互联，例如CPU与CPU之间通过UPI（Ultra Path Interconnect）进行连接，GPU与GPU可以通过PCIe（Intel于2001年开发）/<a href="https://www.nvidia.cn/design-visualization/nvlink-bridges/">NVLink（Nvidia开发）</a>/Infinity Fabric（AMD开发）进行互联，CPU与GPU之间通过PCIe或者<a href="https://zhuanlan.zhihu.com/p/676847465">CXL（Compute Express Link,Intel于2019年提出的高速互联协议）</a>进行互联。超级结点互联能够实现多个计算设备的互联，例如多GPU间的互联可以使用NVLink Switch或RDMA进行互联。</p><p>机间互联通过RDMA（Remote Direct Memory Access）进行互联，RDMA常见的有三种实现：InfiniBand、RoCE、iWarp，使用最为广泛的是IB和RoCE（RoCEv2），RoCE、iWARP，后两者是基于以太网的技术，IB的链路层进行了重新设计。<img src="/2024/08/29/AI%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF/%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF.png"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;三种 RDMA技术RoCE、iWARP，后两者是基于以太网的技术，IB的链路层进行了重新设计。&lt;/p&gt;
&lt;p&gt;随着大模型以及AIGC的快速发展，AI对于算力有了更高的要求。从最开始使用单机单卡（CPU+GPU）进行DL模型训练推理，到使用单机多卡（CPU+GPUs），再到多机多卡的AI集群。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="高速互联技术" scheme="http://example.com/categories/AI/%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF/"/>
    
    <category term="AI服务器高速互联技术分类" scheme="http://example.com/categories/AI/%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF/AI%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF%E5%88%86%E7%B1%BB/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="高速互联技术" scheme="http://example.com/tags/%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>指令集 | CISC与RISC指令集的比较</title>
    <link href="http://example.com/2024/08/29/CISC%E4%B8%8ERISC%E6%8C%87%E4%BB%A4%E9%9B%86%E7%9A%84%E6%AF%94%E8%BE%83/"/>
    <id>http://example.com/2024/08/29/CISC%E4%B8%8ERISC%E6%8C%87%E4%BB%A4%E9%9B%86%E7%9A%84%E6%AF%94%E8%BE%83/</id>
    <published>2024-08-29T12:33:38.000Z</published>
    <updated>2024-08-29T12:40:06.272Z</updated>
    
    <content type="html"><![CDATA[<p>指令集定义了CPU可以执行的指令集合。指令集从复杂度分类可分为CISC和RISC指令集。CISC指令集最常见的是X86，Intel与AMD两大CPU巨头生产的CPU以X86架构为主。RISC指令集有Arm、RISC-V、MIPS、Alpha等，Arm指令集主要应用于移动端、嵌入式计算芯片。</p><span id="more"></span><p>以下是两种不同指令集的比较：</p><table><thead><tr><th align="center"></th><th align="center">CISC</th><th align="center">RISC</th></tr></thead><tbody><tr><td align="center">指令系统</td><td align="center">复杂，庞大</td><td align="center">简单，精简</td></tr><tr><td align="center">指令数量</td><td align="center"><code>&gt;200</code></td><td align="center"><code>&lt;100</code></td></tr><tr><td align="center">指令长度</td><td align="center">不定长</td><td align="center">定长</td></tr><tr><td align="center">可访存指令</td><td align="center">不加限制</td><td align="center">只有load/store指令</td></tr><tr><td align="center">指令执行时间</td><td align="center">相差较大</td><td align="center">大部分在一个周期内完成</td></tr><tr><td align="center">指令使用频率</td><td align="center">相差较大</td><td align="center">都比较常用</td></tr><tr><td align="center">通用寄存器数</td><td align="center">较少</td><td align="center">多</td></tr><tr><td align="center">目标代码</td><td align="center">难以利用编译优化生成高效的目标代码程序</td><td align="center">可采用编译优化生成高效执行的代码</td></tr><tr><td align="center">控制方式</td><td align="center">微程序控制</td><td align="center">组合逻辑控制</td></tr><tr><td align="center">指令流水</td><td align="center">可通过一定方式实现</td><td align="center">必须实现</td></tr></tbody></table>]]></content>
    
    
    <summary type="html">&lt;p&gt;指令集定义了CPU可以执行的指令集合。指令集从复杂度分类可分为CISC和RISC指令集。CISC指令集最常见的是X86，Intel与AMD两大CPU巨头生产的CPU以X86架构为主。RISC指令集有Arm、RISC-V、MIPS、Alpha等，Arm指令集主要应用于移动端、嵌入式计算芯片。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="CPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/"/>
    
    <category term="指令集" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="CISC与RISC指令集的比较" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86/CISC%E4%B8%8ERISC%E6%8C%87%E4%BB%A4%E9%9B%86%E7%9A%84%E6%AF%94%E8%BE%83/"/>
    
    
    <category term="指令集" scheme="http://example.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="ISA" scheme="http://example.com/tags/ISA/"/>
    
    <category term="CISC" scheme="http://example.com/tags/CISC/"/>
    
    <category term="RISC" scheme="http://example.com/tags/RISC/"/>
    
  </entry>
  
  <entry>
    <title>AI模型轻量化 | 模型蒸馏</title>
    <link href="http://example.com/2024/08/29/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/"/>
    <id>http://example.com/2024/08/29/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/</id>
    <published>2024-08-29T12:29:59.000Z</published>
    <updated>2024-08-29T12:33:05.993Z</updated>
    
    <content type="html"><![CDATA[<p><code>模型蒸馏</code>的核心思想是在保持较高预测性能的同时，通过知识迁移的方式，将一个复杂的大模型（<code>教师模型</code>）的知识传授给一个相对简单的小模型（<code>学生模型</code>），极大地降低了模型的复杂性和计算资源需求，实现了模型的轻量化和高效化。</p><span id="more"></span><p>以下是一个简单的模型蒸馏代码示例，使用PyTorch框架实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义教师模型和学生模型</span></span><br><span class="line">teacher_model = model_xxx</span><br><span class="line">student_model = model_xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer_teacher = optim.optimizer1</span><br><span class="line">optimizer_student = optim.optimizer2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据集</span></span><br><span class="line">trainset = datasets.data_xxx</span><br><span class="line">trainloader = torch.utils.data.DataLoader()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 蒸馏过程</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NEPOCH):</span><br><span class="line">    running_loss_teacher = <span class="number">0.0</span></span><br><span class="line">    running_loss_student = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> trainloader:</span><br><span class="line">        <span class="comment"># 教师模型的前向传播</span></span><br><span class="line">        outputs_teacher = teacher_model(inputs)</span><br><span class="line">        loss_teacher = criterion(outputs_teacher, labels)</span><br><span class="line">        running_loss_teacher += loss_teacher.item()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 学生模型的前向传播</span></span><br><span class="line">        outputs_student = student_model(inputs)</span><br><span class="line">        loss_student = criterion(outputs_student, labels) + <span class="number">0.1</span> * torch.<span class="built_in">sum</span>((outputs_teacher - outputs_student) ** <span class="number">2</span>)</span><br><span class="line">        running_loss_student += loss_student.item()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播和参数更新</span></span><br><span class="line">        optimizer_teacher.zero_grad()</span><br><span class="line">        optimizer_student.zero_grad()</span><br><span class="line">        loss_teacher.backward()</span><br><span class="line">        optimizer_teacher.step()</span><br><span class="line">        loss_student.backward()</span><br><span class="line">        optimizer_student.step()</span><br></pre></td></tr></table></figure><p>参考链接1：<a href="https://blog.csdn.net/qq_42533357/article/details/137026170">深度学习中的模型蒸馏技术：实现流程、作用及实践案例-CSDN博客</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;模型蒸馏&lt;/code&gt;的核心思想是在保持较高预测性能的同时，通过知识迁移的方式，将一个复杂的大模型（&lt;code&gt;教师模型&lt;/code&gt;）的知识传授给一个相对简单的小模型（&lt;code&gt;学生模型&lt;/code&gt;），极大地降低了模型的复杂性和计算资源需求，实现了模型的轻量化和高效化。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI模型轻量化" scheme="http://example.com/categories/AI/AI%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/"/>
    
    <category term="模型蒸馏" scheme="http://example.com/categories/AI/AI%E6%A8%A1%E5%9E%8B%E8%BD%BB%E9%87%8F%E5%8C%96/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/"/>
    
    
    <category term="模型蒸馏" scheme="http://example.com/tags/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/"/>
    
    <category term="轻量化" scheme="http://example.com/tags/%E8%BD%BB%E9%87%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>深度学习编译器 | 深度学习编译器与推理引擎的区别</title>
    <link href="http://example.com/2024/08/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://example.com/2024/08/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2024-08-23T14:38:54.000Z</published>
    <updated>2024-08-29T12:17:17.479Z</updated>
    
    <content type="html"><![CDATA[<p>AI编译器与推理引擎的区别。</p><span id="more"></span><p><img src="/2024/08/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/1.png"></p><p><img src="/2024/08/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/2.png"></p><p><img src="/2024/08/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/3.png"></p><p>从整体架构图可以看到，<strong>AI编译器就是针对具体的AI加速芯片硬件，对上层用户接触到的高级语言进行编译，为AI流程实现更加高效的执行，高级语言在AI流程表示的优化是AI编译器的重点。</strong></p><p><img src="/2024/08/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/4.png"></p><p>从整体架构图可以看到，<strong>图优化在推理引擎中占了很小的一部分，推理引擎聚焦于Runtime执行部分和Kernel算子内核层，为不同的硬件提供更加高效、快捷的执行Engine。</strong></p><p>参考链接1：<a href="https://zhuanlan.zhihu.com/p/669347560">AI编译器技术剖析（一）-概述 - 知乎 (zhihu.com)</a></p><p>参考链接2：<a href="https://zhuanlan.zhihu.com/p/629048218">AI编译器和推理引擎的区别 - 知乎 (zhihu.com)</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;AI编译器与推理引擎的区别。&lt;/p&gt;</summary>
    
    
    
    <category term="编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="深度学习编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="深度学习编译器与推理引擎的区别" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%8E%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="编译器" scheme="http://example.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="推理引擎" scheme="http://example.com/tags/%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>VPN | SSL VPN</title>
    <link href="http://example.com/2024/08/23/SSLVPN/"/>
    <id>http://example.com/2024/08/23/SSLVPN/</id>
    <published>2024-08-23T14:33:17.000Z</published>
    <updated>2024-08-29T12:18:48.198Z</updated>
    
    <content type="html"><![CDATA[<p><code>SSL VPN</code>是以<code>SSL</code>加密技术为基础的<code>VPN</code>技术，利用<code>SSL</code>提供的安全机制，为用户<code>远程访问</code>公司内部网络提供了安全保证。</p><p>SSL VPN的典型组网架构如下：</p><p><img src="/2024/08/23/SSLVPN/1.png"></p><span id="more"></span><p>SSL VPN的三种接入方式：</p><ol><li><p>Web接入方式</p><p><img src="/2024/08/23/SSLVPN/2.png"></p></li><li><p>TCP接入方式</p><p><img src="/2024/08/23/SSLVPN/3.png"></p></li><li><p>IP接入方式</p><p><img src="/2024/08/23/SSLVPN/4.png"></p></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;SSL VPN&lt;/code&gt;是以&lt;code&gt;SSL&lt;/code&gt;加密技术为基础的&lt;code&gt;VPN&lt;/code&gt;技术，利用&lt;code&gt;SSL&lt;/code&gt;提供的安全机制，为用户&lt;code&gt;远程访问&lt;/code&gt;公司内部网络提供了安全保证。&lt;/p&gt;
&lt;p&gt;SSL VPN的典型组网架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/08/23/SSLVPN/1.png&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VPN" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/"/>
    
    <category term="SSL VPN" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/SSL-VPN/"/>
    
    
    <category term="VPN" scheme="http://example.com/tags/VPN/"/>
    
    <category term="SSL VPN" scheme="http://example.com/tags/SSL-VPN/"/>
    
  </entry>
  
  <entry>
    <title>智算网络 | Scale up和Scale out网络</title>
    <link href="http://example.com/2024/08/23/Scaleup%E5%92%8CScaleout%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2024/08/23/Scaleup%E5%92%8CScaleout%E7%BD%91%E7%BB%9C/</id>
    <published>2024-08-23T14:29:48.000Z</published>
    <updated>2024-08-23T14:31:41.943Z</updated>
    
    <content type="html"><![CDATA[<p>智算网络包含Scale-up网络和Scale-out网络两张网络。</p><span id="more"></span><p>Scale-up网络描述的是单个机器内GPU、CPU、内存等连接在一起构成的网络，着重单机性能的提升，例如通过增加GPU的数量或增加CPU的数量、增加内存容量来提升单机的计算效率与吞吐量。单机内部不同芯片的连接采用PCIe，GPU之间的连接也可通过NVLink进行连接。</p><p>Scale-out网络描述的是多个算力机器连接起来构成的网络，属于机间互联，目的是为了突破单机性能，通过机间互联合并算力组成一个大的算力网络为大数据处理、大模型训练提供支持。不同机器间的连接可采用RDMA（比较高效的两种是RoCEv2和IB）。</p><p>参考链接1：<a href="https://mp.weixin.qq.com/s/X9if693QD1w3rU3RNDy2Nw">智算网络中Scale-out网络和Scale-up网络的本质区别是什么？</a></p><p>参考链接2：<a href="https://mp.weixin.qq.com/s/fyPFr6aBds3dIV2sc1B6Nw">用于智算场景的Scale-up互联技术分析</a></p><p>参考链接3：<a href="https://mp.weixin.qq.com/s/b6Qf8MD-FG1Ve_PlUyFb2g">CXL，AI时代的“运力”引擎</a></p><p>参考链接4：<a href="https://mp.weixin.qq.com/s/kJZFzX0rWiPtxMkrI8i6TA">Scale-up与Scale-out有什么不同？</a></p><p>参考链接5：<a href="https://mp.weixin.qq.com/s/RyApSIT-wyrEzbiWEsvgZQ">AIGC为什么要区分Scale-out和Scale-up两张网络？</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;智算网络包含Scale-up网络和Scale-out网络两张网络。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="智算中心" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    
    <category term="智算网络：Scale up和Scale out网络" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/%E6%99%BA%E7%AE%97%E7%BD%91%E7%BB%9C%EF%BC%9AScale-up%E5%92%8CScale-out%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="IB" scheme="http://example.com/tags/IB/"/>
    
    <category term="RDMA" scheme="http://example.com/tags/RDMA/"/>
    
    <category term="RoCEv2" scheme="http://example.com/tags/RoCEv2/"/>
    
    <category term="PCIe" scheme="http://example.com/tags/PCIe/"/>
    
    <category term="智算网络" scheme="http://example.com/tags/%E6%99%BA%E7%AE%97%E7%BD%91%E7%BB%9C/"/>
    
    <category term="Scale up" scheme="http://example.com/tags/Scale-up/"/>
    
    <category term="Scale out" scheme="http://example.com/tags/Scale-out/"/>
    
    <category term="AIGC" scheme="http://example.com/tags/AIGC/"/>
    
  </entry>
  
  <entry>
    <title>GPU | CUDA核心与TensorCore的区别</title>
    <link href="http://example.com/2024/08/08/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensorCore%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://example.com/2024/08/08/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensorCore%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2024-08-08T12:45:17.000Z</published>
    <updated>2024-08-08T12:51:05.853Z</updated>
    
    <content type="html"><![CDATA[<p><code>CUDA核心</code>和<code>Tensor Core</code>是<code>NVIDIA GPU</code>中两种不同类型的计算核心且两种核心存在明显的差别，<code>CUDA核心数量</code>和<code>Tensor Core数量</code>是反映GPU计算性能的重要参数，那么CUDA核心与Tensor Core到底是什么？</p><span id="more"></span><p><code>CUDA</code>是<code>NVIDIA</code>发明的<code>并行计算平台</code>和编程模型，<code>CUDA</code>利用<code>GPU</code>强大的<code>并行处理能力</code>提升计算的性能。<code>CUDA核心</code>主要用于执行标准的<code>浮点运算</code>（单精度或双精度），每个<code>CUDA核心</code>每个时钟周期可执行<code>乘加操作</code>，适用于各种<code>通用</code>计算任务。</p><p><code>Tensor Core</code>专为<code>深度学习</code>和<code>AI</code>工作负载设计，用于<code>加速矩阵运算</code>，特别是处理<code>半精度(FP16)</code>和<code>全精度(FP32)</code>的<code>矩阵乘法和累加操作</code>，能够优化<code>深度学习训练和推理</code>过程。第一代<code>Tensor Core</code>是随着<code>Volta</code>架构一起推出的，一代<code>Tensor Core</code>允许两个 4 x 4 FP16 矩阵相乘并添加到一个 4 x 4 FP16 或 FP32 矩阵中（如下图所示），可以实现<code>混合精度训练</code>。</p><p><img src="/2024/08/08/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensorCore%E7%9A%84%E5%8C%BA%E5%88%AB/MAC.png"></p><p>参考链接：<a href="https://developer.volcengine.com/articles/7387624872916353043">一文理解 GPU 张量核心（Tensor Core）</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;CUDA核心&lt;/code&gt;和&lt;code&gt;Tensor Core&lt;/code&gt;是&lt;code&gt;NVIDIA GPU&lt;/code&gt;中两种不同类型的计算核心且两种核心存在明显的差别，&lt;code&gt;CUDA核心数量&lt;/code&gt;和&lt;code&gt;Tensor Core数量&lt;/code&gt;是反映GPU计算性能的重要参数，那么CUDA核心与Tensor Core到底是什么？&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="GPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/"/>
    
    <category term="CUDA核心与Tensor Core的区别" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/CUDA%E6%A0%B8%E5%BF%83%E4%B8%8ETensor-Core%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CUDA" scheme="http://example.com/tags/CUDA/"/>
    
    <category term="Tensor Core" scheme="http://example.com/tags/Tensor-Core/"/>
    
  </entry>
  
  <entry>
    <title>指令集 | 指令集以及国产处理器现状</title>
    <link href="http://example.com/2024/08/08/%E6%8C%87%E4%BB%A4%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E7%8E%B0%E7%8A%B6/"/>
    <id>http://example.com/2024/08/08/%E6%8C%87%E4%BB%A4%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E7%8E%B0%E7%8A%B6/</id>
    <published>2024-08-08T12:40:13.000Z</published>
    <updated>2024-08-29T12:40:40.593Z</updated>
    
    <content type="html"><![CDATA[<ul><li>指令集以及对应的国产处理器<ul><li>CISC<ul><li>X86<ul><li>海光</li><li>兆芯</li></ul></li><li>……</li></ul></li><li>RISC<ul><li>ARM<ul><li>鲲鹏、飞腾、珠峰</li></ul></li><li>RISC-V</li><li>MIPS<ul><li>龙芯 LoongArch</li></ul></li><li>Alpha<ul><li>申威 SW_64</li></ul></li><li>……</li></ul></li></ul></li></ul><span id="more"></span><p>参考链接：<a href="https://mp.weixin.qq.com/s/XA2UtNighbmaAsi2Fua93A">一文读懂面向数据中心的高性能通用RISC-V处理器技术（上）</a></p>]]></content>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;指令集以及对应的国产处理器&lt;ul&gt;
&lt;li&gt;CISC&lt;ul&gt;
&lt;li&gt;X86&lt;ul&gt;
&lt;li&gt;海光&lt;/li&gt;
&lt;li&gt;兆芯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RISC&lt;ul&gt;
&lt;li&gt;ARM&lt;ul&gt;
&lt;li&gt;鲲鹏、飞腾、珠峰&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RISC-V&lt;/li&gt;
&lt;li&gt;MIPS&lt;ul&gt;
&lt;li&gt;龙芯 LoongArch&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Alpha&lt;ul&gt;
&lt;li&gt;申威 SW_64&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="CPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/"/>
    
    <category term="指令集" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="指令集以及国产处理器现状" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E6%8C%87%E4%BB%A4%E9%9B%86/%E6%8C%87%E4%BB%A4%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E7%8E%B0%E7%8A%B6/"/>
    
    
    <category term="指令集" scheme="http://example.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="CISC" scheme="http://example.com/tags/CISC/"/>
    
    <category term="RISC" scheme="http://example.com/tags/RISC/"/>
    
    <category term="X86" scheme="http://example.com/tags/X86/"/>
    
    <category term="ARM" scheme="http://example.com/tags/ARM/"/>
    
    <category term="国产处理器" scheme="http://example.com/tags/%E5%9B%BD%E4%BA%A7%E5%A4%84%E7%90%86%E5%99%A8/"/>
    
    <category term="RISC-V" scheme="http://example.com/tags/RISC-V/"/>
    
  </entry>
  
  <entry>
    <title>后端优化 | 循环优化</title>
    <link href="http://example.com/2024/07/22/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2024/07/22/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/</id>
    <published>2024-07-22T15:23:23.000Z</published>
    <updated>2024-07-22T15:30:28.594Z</updated>
    
    <content type="html"><![CDATA[<p>采用深度学习编译器对深度学习代码进行编译时，在编译器后端会对IR代码进行后端优化，循环优化就包括在后端优化中，后端优化能够加速代码的运行效率。深度学习编译器编译流程如下图所示：</p><span id="more"></span><p><img src="/2024/07/22/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B.png"></p><p>循环优化方式：</p><ul><li><p>循环融合（loop fusion）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sayHello</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sayBye</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;bye&quot;</span>)</span><br><span class="line"><span class="comment"># 融合前</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    sayHello()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    sayBye()</span><br><span class="line"><span class="comment"># 融合后（将两个循环融合为一个）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    sayHello()</span><br><span class="line">    sayBye()</span><br></pre></td></tr></table></figure></li><li><p>循环重新排序（loop reorder）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重排序前</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># 重排序后（采用迭代次数较小的循环驱动内层迭代次数较大的循环能减少内存的消耗）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000000</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li><li><p>循环展开（loop unrolling）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展开前</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    sayHello()</span><br><span class="line"><span class="comment"># 展开后</span></span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br><span class="line">sayHello()</span><br></pre></td></tr></table></figure></li><li><p>循环分块（loop tiling）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_2d_array</span>(<span class="params">n, A</span>):</span></span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="built_in">sum</span> += A[i][j]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_2d_array</span>(<span class="params">n, A</span>) &#123;</span></span><br><span class="line"><span class="function">    <span class="title">sum</span> = 0</span></span><br><span class="line"><span class="function">    <span class="title">block_size</span> = 8</span></span><br><span class="line"><span class="function">    <span class="title">for</span> <span class="title">i</span> <span class="title">in</span> <span class="title">range</span>(<span class="params"><span class="number">0</span>, n, block_size</span>):</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n, block_size):</span><br><span class="line">    <span class="keyword">for</span> bi <span class="keyword">in</span> <span class="built_in">range</span>(i, i + block_size):</span><br><span class="line">    <span class="keyword">for</span> bj <span class="keyword">in</span> <span class="built_in">range</span>(j, j + block_size):</span><br><span class="line">    <span class="built_in">sum</span> += A[bi][bj]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;采用深度学习编译器对深度学习代码进行编译时，在编译器后端会对IR代码进行后端优化，循环优化就包括在后端优化中，后端优化能够加速代码的运行效率。深度学习编译器编译流程如下图所示：&lt;/p&gt;</summary>
    
    
    
    <category term="编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="深度学习编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="后端优化" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="循环优化" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="编译器" scheme="http://example.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="后端优化" scheme="http://example.com/tags/%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="循环优化" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"/>
    
    <category term="循环融合" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E8%9E%8D%E5%90%88/"/>
    
    <category term="循环重排序" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
    <category term="循环展开" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80/"/>
    
    <category term="循环分块" scheme="http://example.com/tags/%E5%BE%AA%E7%8E%AF%E5%88%86%E5%9D%97/"/>
    
  </entry>
  
  <entry>
    <title>RDMA | IB与RoCEv2的对比</title>
    <link href="http://example.com/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    <id>http://example.com/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/</id>
    <published>2024-07-22T15:22:55.000Z</published>
    <updated>2024-07-22T15:27:11.741Z</updated>
    
    <content type="html"><![CDATA[<p>Nvidia Infiniband 与 RoCEv2的对比：</p><p><img src="/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94.png"></p><p>参考链接：<a href="https://mp.weixin.qq.com/s/kzcrq9ycET_K7TrIQT_nSg">Infiniband和RoCEv2，以及RDMA技术的未来</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Nvidia Infiniband 与 RoCEv2的对比：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/07/22/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%E6%AF%94/IB%E4%B8%8ERDMA%E7%9A%84%E5%AF%B9%</summary>
      
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="RDMA" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RDMA/"/>
    
    <category term="IB与RoCEv2的对比" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/RDMA/IB%E4%B8%8ERoCEv2%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    
    
    <category term="IB" scheme="http://example.com/tags/IB/"/>
    
    <category term="RDMA" scheme="http://example.com/tags/RDMA/"/>
    
    <category term="RoCEv2" scheme="http://example.com/tags/RoCEv2/"/>
    
  </entry>
  
  <entry>
    <title>TVM | TVM介绍</title>
    <link href="http://example.com/2024/07/22/TVM%E4%BB%8B%E7%BB%8D/"/>
    <id>http://example.com/2024/07/22/TVM%E4%BB%8B%E7%BB%8D/</id>
    <published>2024-07-22T15:22:16.000Z</published>
    <updated>2024-07-22T15:25:11.708Z</updated>
    
    <content type="html"><![CDATA[<p>参考文章：<a href="https://www.zhihu.com/question/532085071/answer/3154629417">(38 封私信 / 80 条消息) 深度学习编译器研发工程师的工作主要是集中于编译技术的前端、中端还是后端？ - 知乎 (zhihu.com)</a></p><p>参考视频：<a href="https://www.bilibili.com/video/BV1u6421M7jN/?spm_id_from=333.788&vd_source=0d5e0d352ee1cac3b12442c119f31bfc">【3rd-party】20240215 深度学习编译技术及TVM实践分享_哔哩哔哩_bilibili</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;参考文章：&lt;a href=&quot;https://www.zhihu.com/question/532085071/answer/3154629417&quot;&gt;(38 封私信 / 80 条消息) 深度学习编译器研发工程师的工作主要是集中于编译技术的前端、中端还是后端？ - 知乎 (zh</summary>
      
    
    
    
    <category term="编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="深度学习编译器" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="TVM" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/TVM/"/>
    
    <category term="TVM介绍" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%99%A8/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/TVM/TVM%E4%BB%8B%E7%BB%8D/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="编译器" scheme="http://example.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="TVM" scheme="http://example.com/tags/TVM/"/>
    
  </entry>
  
  <entry>
    <title>CUDA | CUDA的新竞争者</title>
    <link href="http://example.com/2024/07/19/CUDA%E7%9A%84%E6%96%B0%E7%AB%9E%E4%BA%89%E8%80%85/"/>
    <id>http://example.com/2024/07/19/CUDA%E7%9A%84%E6%96%B0%E7%AB%9E%E4%BA%89%E8%80%85/</id>
    <published>2024-07-19T15:23:07.000Z</published>
    <updated>2024-07-19T15:34:11.360Z</updated>
    
    <content type="html"><![CDATA[<p>AI时代，Nvidia作为HPC的头号玩家，其手中的主要利器有：高算力GPU、高速互联设备、CUDA，其中CUDA可以称之为Nvidia的护城河，只有使用CUDA才能利用Nvidia GPU进行高效的运行AI算法。</p><span id="more"></span><p>2024.7.12 英国公司Spectral Compute发布了<a href="[SCALE GPGPU Programming Language (scale-lang.com)](https://scale-lang.com/posts/2024-07-12-release-announcement)">SCALE BETA</a>，意图突破Nvidia的护城河-CUDA。SCALE是一个GPGPU工具链，它允许CUDA程序原生地运行在AMD GPUs上，后期也会提供其他厂商GPU的支持。SCALE的开发主要是为了让用户能够自由地使用GPGPU编程工具和GPU硬件，这些工具和硬件最好地满足了用户的开发需求。SCALE的横空出世，使得“Write once, run anywhere”对GPU来说称为可能。Spectral Compute公司计划通过跨越CUDA编程语言和其他厂商硬件之间的兼容性差距来实现“Write once, run anywhere”。</p><p>SCALE是一个类似于Nvidia CUDA工具的GPGPU工具，该工具能够将CUDA代码编译成面向非Nvidia GPUs的二进制代码。SCALE旨在与CUDA源代码兼容，包括支持内联PTX和NVCC的C++特性。</p><p>SCALE工具允许在其他厂商的GPU上运行CUDA code，打破必须使用与CUDA绑定的Nvidia硬件，这促进了AI算法开发以及部署的灵活度，可根据市场GPU的存量以及自身经济能力灵活的选择算力设备。</p><p>SCALE 文档：<a href="https://docs.scale-lang.com/examples/">SCALE Example Programs - SCALE documentation (scale-lang.com)</a></p><p>参考链接：<a href="https://mp.weixin.qq.com/s/y2M0bqTMzWC6F4sOkw2yHw">突破CUDA包围圈，再出一招</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;AI时代，Nvidia作为HPC的头号玩家，其手中的主要利器有：高算力GPU、高速互联设备、CUDA，其中CUDA可以称之为Nvidia的护城河，只有使用CUDA才能利用Nvidia GPU进行高效的运行AI算法。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI工具链" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/"/>
    
    <category term="CUDA" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/CUDA/"/>
    
    <category term="CUDA新的竞争者" scheme="http://example.com/categories/AI/AI%E5%B7%A5%E5%85%B7%E9%93%BE/CUDA/CUDA%E6%96%B0%E7%9A%84%E7%AB%9E%E4%BA%89%E8%80%85/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CUDA" scheme="http://example.com/tags/CUDA/"/>
    
    <category term="Nvidia" scheme="http://example.com/tags/Nvidia/"/>
    
    <category term="SCALE" scheme="http://example.com/tags/SCALE/"/>
    
    <category term="HPC" scheme="http://example.com/tags/HPC/"/>
    
  </entry>
  
  <entry>
    <title>AI基础设施 | 什么是智算中心</title>
    <link href="http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    <id>http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/</id>
    <published>2024-07-19T15:22:56.000Z</published>
    <updated>2024-07-19T15:37:22.379Z</updated>
    
    <content type="html"><![CDATA[<ol><li>三种数据中心<ul><li>通算中心（通用服务器-以CPU为主要芯片）</li><li>智算中心（智算服务器-以GPU/NPU/TPU等加速芯片为主）</li><li>超算中心（超级计算机）</li></ul></li></ol><span id="more"></span><ol start="2"><li><p>为什么要有智算中心？</p><ul><li><p>应用类型变化：传统应用以web应用为主，部署在以CPU为核心算力的通用服务器上。随着AI的快速发展，AI Native类型的应用快速占领市场，AI Native应用需要更多的算力。</p></li><li><p>传统服务器算力不足：大模型、其他AI算法的训练、推理过程需要更大的算力支撑，传统的通用服务器算力不能满足模型的训练和推理，因此需要构建拥有强大算力、高带宽通信的智算中心。</p></li></ul></li></ol><ol start="3"><li><p>什么是智算中心？</p><p><code>智算中心</code>由智算服务器组成，是以<code>人工智能</code>计算任务为主的<code>数据中心</code>。智算中心采用专门的AI算力硬件（<code>GPU</code>/<code>NPU</code>/<code>TPU</code>），适合高效运行AI算法，可以用于计算机视觉（Computer Vision）、自然语言处理（Natural Language Processing）、机器学习（Machine Learning）等领域，处理图像识别（Image Recognition）、语音识别（Speech Recognition）、文本分析（Text Analysis）、模型训练推理（Model Training and Inferring）等任务。</p></li></ol><ol start="4"><li><p>智算中心的核心-智算服务器：</p><ul><li><p>训练服务器（AI算力板卡多于推理服务器）：用于AI模型训练</p></li><li><p>推理服务器：用于AI算法推理</p></li><li><p>训推一体服务器：用于AI算法的训练和推理</p></li><li><p>算力大小：训练服务器 &gt;= 训推一体服务器 &gt; 推理服务器</p></li></ul></li></ol><p>参考链接：<a href="https://mp.weixin.qq.com/s/pbxWZvnRF1BMLQlwADxsNw">四问四答，彻底看懂智算中心！</a></p>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;三种数据中心&lt;ul&gt;
&lt;li&gt;通算中心（通用服务器-以CPU为主要芯片）&lt;/li&gt;
&lt;li&gt;智算中心（智算服务器-以GPU/NPU/TPU等加速芯片为主）&lt;/li&gt;
&lt;li&gt;超算中心（超级计算机）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="智算中心" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    
    <category term="什么是智算中心？" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/%E4%BB%80%E4%B9%88%E6%98%AF%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83%EF%BC%9F/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="智算中心" scheme="http://example.com/tags/%E6%99%BA%E7%AE%97%E4%B8%AD%E5%BF%83/"/>
    
    <category term="智算服务器" scheme="http://example.com/tags/%E6%99%BA%E7%AE%97%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>VPN | 什么是VPN</title>
    <link href="http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AFVPN/"/>
    <id>http://example.com/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AFVPN/</id>
    <published>2024-07-19T15:22:34.000Z</published>
    <updated>2024-07-19T15:30:56.892Z</updated>
    
    <content type="html"><![CDATA[<p>在工作、或学习中，如果连接的是内部网络，则可以直接访问内部网络资源，如果在家或出差时想要访问内部网络资源，常需要通过<code>VPN</code>才能访问公司/学校<code>内部网络资源</code>。那么VPN到底是什么呢？</p><span id="more"></span><p>VPN（Virtual Private Network）: 一种利用<code>公共网络</code>建立<code>专用网络</code>的技术。通过加密和隧道技术，VPN可以保护<code>数据传输的安全性和隐私性</code>，同时能够使<code>远程</code>用户安全访问企业/学校的内部网络资源。 </p><p>VPN的应用场景：</p><ol><li>远程工作</li><li>数据保护</li><li>隐私保护</li></ol><p>工作原理：</p><p>VPN通过创建一个加密的隧道来传输数据，确保数据在传输过程中的安全和隐私。VPN用户连接到VPN服务器后，所有网络流量都会被加密并通过隧道传输到VPN服务器，然后再解密和转发到互联网或内部网络</p><p><img src="/2024/07/19/%E4%BB%80%E4%B9%88%E6%98%AFVPN/VPN.png"></p><p>VPN分类以及区别：</p><ul><li>IPSec VPN(Internet Protocol Security VPN，互联网协议安全VPN)</li><li>SSL/TLS VPN（SSL-VPN,Secure Socket Layer, 安全套接层VPN）</li></ul><p>![](./什么是VPN/two types VPN.png)</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在工作、或学习中，如果连接的是内部网络，则可以直接访问内部网络资源，如果在家或出差时想要访问内部网络资源，常需要通过&lt;code&gt;VPN&lt;/code&gt;才能访问公司/学校&lt;code&gt;内部网络资源&lt;/code&gt;。那么VPN到底是什么呢？&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VPN" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/"/>
    
    <category term="什么是VPN？" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/VPN/%E4%BB%80%E4%B9%88%E6%98%AFVPN%EF%BC%9F/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="VPN" scheme="http://example.com/tags/VPN/"/>
    
    <category term="SSL VPN" scheme="http://example.com/tags/SSL-VPN/"/>
    
    <category term="IPsec VPN" scheme="http://example.com/tags/IPsec-VPN/"/>
    
  </entry>
  
  <entry>
    <title>TCP/IP | 秒懂TCPIP</title>
    <link href="http://example.com/2024/07/19/%E7%A7%92%E6%87%82TCPIP/"/>
    <id>http://example.com/2024/07/19/%E7%A7%92%E6%87%82TCPIP/</id>
    <published>2024-07-19T15:22:22.000Z</published>
    <updated>2024-07-19T15:25:13.411Z</updated>
    
    <content type="html"><![CDATA[<p>数据包传输过程中都用到了哪些协议？</p><p><a href="https://mp.weixin.qq.com/s/dysSZLyTRaSbr4650aQ7uA">全网介绍TCP/IP最全的文章</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;数据包传输过程中都用到了哪些协议？&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/dysSZLyTRaSbr4650aQ7uA&quot;&gt;全网介绍TCP/IP最全的文章&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机网络" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="TCP/IP" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-IP/"/>
    
    <category term="秒懂TCPIP" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-IP/%E7%A7%92%E6%87%82TCPIP/"/>
    
    
    <category term="计算机网络" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    <category term="TCP/IP" scheme="http://example.com/tags/TCP-IP/"/>
    
    <category term="数据包" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%8C%85/"/>
    
    <category term="协议" scheme="http://example.com/tags/%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式训练集合通信以及集合通信原语</title>
    <link href="http://example.com/2024/07/17/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E4%BB%A5%E5%8F%8A%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/"/>
    <id>http://example.com/2024/07/17/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E4%BB%A5%E5%8F%8A%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/</id>
    <published>2024-07-17T12:09:13.000Z</published>
    <updated>2024-07-17T12:10:17.217Z</updated>
    
    <content type="html"><![CDATA[<p><code>大模型</code>的训练需要用到多个配有<code>GPU</code>的节点，GPU间通过<code>集合通信原语</code>进行通信，从而实现<code>GPU</code>间的<code>数据交换</code>和<code>共享</code>。</p><span id="more"></span><p><code>通信原语</code>的具体内容参考：<a href="https://zhuanlan.zhihu.com/p/493092647">分布式训练 – 第3篇 - 分布式训练常用的集合通信及其通信原语 - 知乎 (zhihu.com)</a>，这篇文章分析、总结的非常到位，此处不再额外总结。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;大模型&lt;/code&gt;的训练需要用到多个配有&lt;code&gt;GPU&lt;/code&gt;的节点，GPU间通过&lt;code&gt;集合通信原语&lt;/code&gt;进行通信，从而实现&lt;code&gt;GPU&lt;/code&gt;间的&lt;code&gt;数据交换&lt;/code&gt;和&lt;code&gt;共享&lt;/code&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="深度学习" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大模型" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="分布式训练" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"/>
    
    <category term="集合通信以及集合通信原语" scheme="http://example.com/categories/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E4%BB%A5%E5%8F%8A%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/"/>
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="大模型" scheme="http://example.com/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="通信原语" scheme="http://example.com/tags/%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD/"/>
    
    <category term="集合通信" scheme="http://example.com/tags/%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>CPU | CPU的组成以及功能</title>
    <link href="http://example.com/2024/07/16/CPU%E7%9A%84%E7%BB%84%E6%88%90%E4%BB%A5%E5%8F%8A%E5%8A%9F%E8%83%BD/"/>
    <id>http://example.com/2024/07/16/CPU%E7%9A%84%E7%BB%84%E6%88%90%E4%BB%A5%E5%8F%8A%E5%8A%9F%E8%83%BD/</id>
    <published>2024-07-16T12:12:08.000Z</published>
    <updated>2024-07-16T12:13:16.493Z</updated>
    
    <content type="html"><![CDATA[<p>回顾一下CPU的组成以及各组件的功能。</p><span id="more"></span><p><code>CPU</code>由<code>运算器</code>(arithmetic unit) 和<code>控制器</code>(controller)组成，运算器负责对数据进行加工处理(加减乘除等<code>算数运算</code>、与或非等<code>逻辑运算</code>)，控制器负责解析指令并向运算器或者存储器发出控制信号。</p><p><strong>运算器的组成及各部分的功能</strong>：</p><ul><li><p><code>乘商寄存器MQ</code>(Mulitple Quotient Register)：用于存放<code>乘、除法</code>运算时的操作数或运算结果</p></li><li><p><code>累加器ACC</code>(Accumulator)：用于存放<code>加、减法</code>运算的操作数或运算结果</p></li><li><p><code>算术逻辑单元ALU</code>(Arithmetic Logic Unit)：通过内部复杂的<code>电路实现算数运算、逻辑运算</code></p></li><li><p><code>通用寄存器X</code>：用于存放操作数</p></li><li><p>``程序状态字PSW<code>(Program State Word)：一个</code>特殊的寄存器<code>，用于存储CPU执行指令时的一些</code>重要状态信息<code>和</code>标志位<code>。PSW在指令执行过程中被不断地更新，以</code>反应当前指令执行的状态和结果`。</p><ul><li>PSW的重要标志位<ul><li>零标志位（ZF）：当运算结果为<code>0</code>时，ZF被置为1，否则为0</li><li>符号标志位（SF）：当运算结果为<code>负数</code>时，SF被置为1，否则为0</li><li>进位标志位（CF）：在<code>无符号加法和减法</code>中，当结果超出了所能表示的范围时，CF被置为1，否则为0</li><li>移除标志位（OF）：在<code>有符号加法和减法</code>中，当结果超出了所能表示的范围时，OF被置为1，否则为0</li><li>奇偶标志位（PF）：当运算结果中1的个数为偶数时，PF被置为1，否则为0</li></ul></li></ul></li><li><p>运算器中不同寄存器存放的操作数类型</p><table><thead><tr><th align="center"></th><th align="center">加</th><th align="center">减</th><th align="center">乘</th><th align="center">除</th></tr></thead><tbody><tr><td align="center">ACC</td><td align="center">被加数、和</td><td align="center">被减数、差</td><td align="center">乘积高位</td><td align="center">被除数、除数</td></tr><tr><td align="center">MQ</td><td align="center"></td><td align="center"></td><td align="center">乘数、乘积低位</td><td align="center">商</td></tr><tr><td align="center">X</td><td align="center">加数</td><td align="center">减数</td><td align="center">被乘数</td><td align="center">除数</td></tr></tbody></table></li></ul><p><strong>控制器的组成及各部分的功能</strong>：</p><ul><li>控制单元CU（Contorl Unit）：分析指令，给出控制信号</li><li>指令寄存器IR（Instruction Register）：存放当前执行指令</li><li>程序计数器PC（Program Counter）：存放指令地址，有自动加一功能</li></ul><p><strong>以计算加法运算“1+1”为例</strong>：</p><ol><li>CPU根据PC中的地址，将存储器中的指令“1+1”搬运到指令寄存器IR中（PC自动+1,指向下一条需要执行的指令）</li><li>CPU的CU对IR中的指令进行分析，将被加数1放入运算器的ACC中，将加数放入X中</li><li>CU控制ALU对ACC、X中的操作数进行运算，并将运算后的结果放入ACC中（此时PSW的一些标志位的值：ZF=0,SF=0,CF=0,PF=0）</li><li>CPU将ACC中的结果搬运到存储器中，完成本次运算</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;回顾一下CPU的组成以及各组件的功能。&lt;/p&gt;</summary>
    
    
    
    <category term="计算机基础" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="计算机组成原理" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    <category term="CPU" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/CPU/"/>
    
    <category term="CPU的组成以及各组件的功能" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/CPU/CPU%E7%9A%84%E7%BB%84%E6%88%90%E4%BB%A5%E5%8F%8A%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E5%8A%9F%E8%83%BD/"/>
    
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="运算器" scheme="http://example.com/tags/%E8%BF%90%E7%AE%97%E5%99%A8/"/>
    
    <category term="CU" scheme="http://example.com/tags/CU/"/>
    
    <category term="控制器" scheme="http://example.com/tags/%E6%8E%A7%E5%88%B6%E5%99%A8/"/>
    
    <category term="controller" scheme="http://example.com/tags/controller/"/>
    
    <category term="算数运算" scheme="http://example.com/tags/%E7%AE%97%E6%95%B0%E8%BF%90%E7%AE%97/"/>
    
    <category term="逻辑运算" scheme="http://example.com/tags/%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>加速芯片 | 不同加速芯片的特点</title>
    <link href="http://example.com/2024/07/15/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/"/>
    <id>http://example.com/2024/07/15/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/</id>
    <published>2024-07-15T12:25:06.000Z</published>
    <updated>2024-07-15T12:34:00.345Z</updated>
    
    <content type="html"><![CDATA[<p>当前，<code>AI服务器</code>的芯片构成为”<code>CPU+加速芯片</code>“，加速芯片主要有<code>CPU</code>、<code>FPGA</code>和<code>ASIC</code>等加速芯片，利用CPU与加速芯片的组合可以满足高吞吐量互联的需求，从而加速模型的训练（training）、推理（Inference）过程。</p><span id="more"></span><p>CPU中有大量的<code>缓存</code>和复杂的<code>逻辑控制单元</code>，擅长<strong>逻辑控制、串行运算</strong>,但CPU的<strong>算力小</strong>，<strong>不擅长复杂算法运算和并行运算</strong>，因此在AI模型的训练过程中需要加速芯片来加速大量数据的计算，加速算法的演进和模型的更新。</p><p>CPU以及加速芯片（GPU、存算一体芯片）的架构：</p><p><img src="/2024/07/15/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/%E4%B8%8D%E5%90%8C%E8%8A%AF%E7%89%87%E7%9A%84%E6%9E%B6%E6%9E%84.png"></p><p>About 存算一体性芯片：大模型训练的过程是算法学习大数据中规律的过程，训练时间主要花费在<code>数据处理（学习）</code>和<code>数据搬运（在device和host之间搬运数据）</code>上，大模型的训练数据集往往非常庞大，<code>存算一体芯片</code>将计算单元需要的数据“放在自己身边”，减少芯片内外的数据搬运，从而提升了模型的训练效率。</p><p>不同AI加速芯片的优缺点：</p><table><thead><tr><th align="center">芯片类别（chips category）</th><th align="center">优点（advantages）</th><th align="center">缺点（disadvantages）</th><th align="center">产品</th></tr></thead><tbody><tr><td align="center">GPU</td><td align="center">支持大量<strong>并行计算</strong>（浮点运算能力）</td><td align="center"><strong>管理控制能力弱</strong>（CPU具备较强的管理控制能力），功耗高</td><td align="center">Nvidia A100、Nvidia H100等</td></tr><tr><td align="center">FPGA</td><td align="center">可重复编程、低延时、硬件可根据需求调整、<strong>灵活性最高</strong></td><td align="center">开发难度大、<strong>定点运算</strong>、价格贵</td><td align="center">Intel Arria 10等</td></tr><tr><td align="center">ASIC</td><td align="center">成本低、能耗低、性能强、<strong>针对AI设定特定架构</strong></td><td align="center">灵活性不够，价格高于FPGA</td><td align="center">谷歌TPU、华为昇腾910等</td></tr></tbody></table><p>参考链接：<a href="https://mp.weixin.qq.com/s/mkfVi3r9ehu67JpvlPG6_Q">AI 大模型算力芯片产业深度分析 2024</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;当前，&lt;code&gt;AI服务器&lt;/code&gt;的芯片构成为”&lt;code&gt;CPU+加速芯片&lt;/code&gt;“，加速芯片主要有&lt;code&gt;CPU&lt;/code&gt;、&lt;code&gt;FPGA&lt;/code&gt;和&lt;code&gt;ASIC&lt;/code&gt;等加速芯片，利用CPU与加速芯片的组合可以满足高吞吐量互联的需求，从而加速模型的训练（training）、推理（Inference）过程。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="不同加速芯片的特点" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/%E4%B8%8D%E5%90%8C%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87%E7%9A%84%E7%89%B9%E7%82%B9/"/>
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="加速芯片" scheme="http://example.com/tags/%E5%8A%A0%E9%80%9F%E8%8A%AF%E7%89%87/"/>
    
    <category term="存算一体" scheme="http://example.com/tags/%E5%AD%98%E7%AE%97%E4%B8%80%E4%BD%93/"/>
    
    <category term="FPGA" scheme="http://example.com/tags/FPGA/"/>
    
    <category term="ASIC" scheme="http://example.com/tags/ASIC/"/>
    
  </entry>
  
  <entry>
    <title>CPU | 三条国产CPU发展路线</title>
    <link href="http://example.com/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/"/>
    <id>http://example.com/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/</id>
    <published>2024-07-15T12:20:28.000Z</published>
    <updated>2024-07-15T12:34:19.827Z</updated>
    
    <content type="html"><![CDATA[<p>三条国产CPU发展路线：</p><p><img src="/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/%E4%B8%8D%E5%90%8CCPU%E7%9A%84%E6%9E%B6%E6%9E%84.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;三条国产CPU发展路线：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2024/07/15/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/%E4%B8%8D%E5%90%8CC</summary>
      
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="CPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/"/>
    
    <category term="三条国产CPU发展路线" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/CPU/%E4%B8%89%E6%9D%A1%E5%9B%BD%E4%BA%A7CPU%E5%8F%91%E5%B1%95%E8%B7%AF%E7%BA%BF/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="指令集" scheme="http://example.com/tags/%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
    
    <category term="CISC" scheme="http://example.com/tags/CISC/"/>
    
    <category term="RISC" scheme="http://example.com/tags/RISC/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="国产" scheme="http://example.com/tags/%E5%9B%BD%E4%BA%A7/"/>
    
    <category term="X86" scheme="http://example.com/tags/X86/"/>
    
    <category term="ARM" scheme="http://example.com/tags/ARM/"/>
    
    <category term="MIPS" scheme="http://example.com/tags/MIPS/"/>
    
    <category term="兆芯" scheme="http://example.com/tags/%E5%85%86%E8%8A%AF/"/>
    
    <category term="海光" scheme="http://example.com/tags/%E6%B5%B7%E5%85%89/"/>
    
    <category term="鲲鹏" scheme="http://example.com/tags/%E9%B2%B2%E9%B9%8F/"/>
    
    <category term="飞腾" scheme="http://example.com/tags/%E9%A3%9E%E8%85%BE/"/>
    
    <category term="龙芯" scheme="http://example.com/tags/%E9%BE%99%E8%8A%AF/"/>
    
    <category term="申威" scheme="http://example.com/tags/%E7%94%B3%E5%A8%81/"/>
    
  </entry>
  
  <entry>
    <title>高速互联 | PCIe与NVLink的对比</title>
    <link href="http://example.com/2024/07/15/PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    <id>http://example.com/2024/07/15/PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/</id>
    <published>2024-07-15T12:13:52.000Z</published>
    <updated>2024-07-15T12:34:33.070Z</updated>
    
    <content type="html"><![CDATA[<p><code>AI</code>算法极大程度上依赖于<code>大数据</code>（<code>Big Data</code>）,AI 算法的训练对机器的<code>算力</code>以及数据传输能力有着非常高的要求。算力问题的解决是通过提升<code>GPU</code>、<code>NPU</code>的计算能力，并且将多块<code>GPU/NPU</code>连接起来组成一个<code>算力网络</code>（Computing Force Network, <code>CFN</code>）。算力网络中的不同GPU/NPU需要进行互联，GPU/NPU也需要与CPU进行互联，从而共同协作完成大量数据的运算。</p><span id="more"></span><p>目前的<code>GPU互联方式</code>主要有两种：<code>PCIe</code>和<code>NVLink</code>，<strong>在同一个机器内，PCIe负责CPU与GPU之间的通信，NVlink负责GPU与GPU之间的通信。机器间的通信可通过TCP/IP网络协议或RDMA网络协议（InfiniBand、iWARP、RoCE）进行。</strong></p><p><img src="/2024/07/15/PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/NVLink.png"></p><ol><li><p>PCIe（PCI-Express）</p><ul><li><p>Peripheral Component Interconnect Express的简称，它是一种<code>内部总线</code>，也是一种<code>计算机扩展总线标准</code>，是一种<code>高速串行</code>、<code>高带宽</code>扩展总线，通常用于主板上连接<code>显卡</code>、<code>固态硬盘</code>以及采集卡和<code>无线网卡</code>等外设。</p></li><li><p>PCIe的两种存在形式：<code>M.2接口</code>和<code>PCIe标准插槽</code>。<code>加速卡</code>、<code>高带宽网卡</code>和<code>显卡</code>一般都是安装在<code>插槽</code>中。<code>固态硬盘</code>、<code>笔记本网卡</code>等一般使用<code>M.2接口</code>。</p></li><li><p>PCIe数据传输速率</p><table><thead><tr><th align="center">协议（Protocol）</th><th align="center">传输速率/Gbps</th></tr></thead><tbody><tr><td align="center">PCIe1.0</td><td align="center">2.5</td></tr><tr><td align="center">PCIe2.0</td><td align="center">5.0</td></tr><tr><td align="center">PCIe3.0</td><td align="center"><strong>8.0</strong></td></tr><tr><td align="center">PCIe4.0</td><td align="center">16</td></tr><tr><td align="center">PCIe5.0</td><td align="center">32</td></tr><tr><td align="center">PCIe6.0</td><td align="center">64</td></tr></tbody></table></li></ul></li><li><p>NVLink</p><ul><li><p><code>NVLink</code> 是一种<code>高速互连</code>技术，旨在加快 <code>CPU 与 GPU</code>、<code>GPU 与 GPU</code> 之间的数据传输速度，提高系统性能。</p></li><li><p>NVLink高速互联的两种形式：直连、NVSwitch。</p></li><li><p>NVLink数据传输速率</p><table><thead><tr><th align="center">协议（Protocol）</th><th align="center">发布时间</th><th align="center">显卡</th><th align="center">最大链数</th><th align="center">GPU之间总带宽</th><th align="center">应用架构</th></tr></thead><tbody><tr><td align="center">NVLink 1.0</td><td align="center">2016</td><td align="center">P100</td><td align="center">4</td><td align="center">160GB/s</td><td align="center">Pascal</td></tr><tr><td align="center">NVLink 2.0</td><td align="center">2017</td><td align="center">V100</td><td align="center">6</td><td align="center">300GB/s</td><td align="center">Volta</td></tr><tr><td align="center">NVLink 3.0</td><td align="center">2020</td><td align="center">A100</td><td align="center">12</td><td align="center">600GB/s</td><td align="center">Ampere</td></tr><tr><td align="center">NVLink 4.0</td><td align="center">2022</td><td align="center">H100</td><td align="center">18</td><td align="center">900GB/s</td><td align="center">Hopper</td></tr><tr><td align="center">NVLink 5.0</td><td align="center">2024</td><td align="center">GB200</td><td align="center">18</td><td align="center">1800GB/s</td><td align="center">Blackwell</td></tr></tbody></table></li></ul><p>![](./PCIe与NVLink的对比/NVLink Performance.png)</p></li><li><p>PCIe VS NVLink</p><p>![](./PCIe与NVLink的对比/PCIe VS NVLink.png)</p></li></ol><p>参考链接1：<a href="https://mp.weixin.qq.com/s/leRVFe9_ETxIOUvv3Wjecw">AI服务器内部“高速公路”：PCIe和NVLink技术！</a></p><p>参考链接2：<a href="https://www.nvidia.cn/data-center/nvlink/">NVLink 和 NVSwitch：卓越的 HPC 数据中心平台 | NVIDIA</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;AI&lt;/code&gt;算法极大程度上依赖于&lt;code&gt;大数据&lt;/code&gt;（&lt;code&gt;Big Data&lt;/code&gt;）,AI 算法的训练对机器的&lt;code&gt;算力&lt;/code&gt;以及数据传输能力有着非常高的要求。算力问题的解决是通过提升&lt;code&gt;GPU&lt;/code&gt;、&lt;code&gt;NPU&lt;/code&gt;的计算能力，并且将多块&lt;code&gt;GPU/NPU&lt;/code&gt;连接起来组成一个&lt;code&gt;算力网络&lt;/code&gt;（Computing Force Network, &lt;code&gt;CFN&lt;/code&gt;）。算力网络中的不同GPU/NPU需要进行互联，GPU/NPU也需要与CPU进行互联，从而共同协作完成大量数据的运算。&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://example.com/categories/AI/"/>
    
    <category term="AI基础设施" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"/>
    
    <category term="GPU" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/"/>
    
    <category term="GPU高速互联-PCIe与NVLink的对比" scheme="http://example.com/categories/AI/AI%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/GPU/GPU%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94-PCIe%E4%B8%8ENVLink%E7%9A%84%E5%AF%B9%E6%AF%94/"/>
    
    
    <category term="AI" scheme="http://example.com/tags/AI/"/>
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
    <category term="高速互联" scheme="http://example.com/tags/%E9%AB%98%E9%80%9F%E4%BA%92%E8%81%94/"/>
    
    <category term="PCIe" scheme="http://example.com/tags/PCIe/"/>
    
    <category term="NVLink" scheme="http://example.com/tags/NVLink/"/>
    
    <category term="InfiniBand" scheme="http://example.com/tags/InfiniBand/"/>
    
    <category term="iWARP" scheme="http://example.com/tags/iWARP/"/>
    
    <category term="RoCE" scheme="http://example.com/tags/RoCE/"/>
    
    <category term="模型" scheme="http://example.com/tags/%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="CFN" scheme="http://example.com/tags/CFN/"/>
    
    <category term="NPU" scheme="http://example.com/tags/NPU/"/>
    
    <category term="NVSwitch" scheme="http://example.com/tags/NVSwitch/"/>
    
  </entry>
  
</feed>
